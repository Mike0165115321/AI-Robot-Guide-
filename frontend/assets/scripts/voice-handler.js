class VoiceHandler {
    /**
     * @param {AudioContext} audioContext - [à¹à¸à¹‰à¹„à¸‚] à¸£à¸±à¸š AudioContext à¸—à¸µà¹ˆà¸ªà¸£à¹‰à¸²à¸‡à¸ˆà¸²à¸à¸‚à¹‰à¸²à¸‡à¸™à¸­à¸
     * @param {object} callbacks - à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™ Callback à¸•à¹ˆà¸²à¸‡à¹†
     * @param {function} callbacks.onStatusUpdate
     * @param {function} callbacks.onSpeechEnd
     * @param {object} options - à¸à¸²à¸£à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² VAD
     */
    constructor(audioContext, callbacks, options = {}) { // ðŸ‘ˆ [à¹à¸à¹‰à¹„à¸‚] à¹€à¸žà¸´à¹ˆà¸¡ audioContext
        if (!audioContext) {
            throw new Error("VoiceHandler requires a valid AudioContext to be provided.");
        }

        this.callbacks = { onStatusUpdate: () => { }, onSpeechEnd: () => { }, ...callbacks };

        const defaults = {
            NOISE_FLOOR: 0.02,
            SPEECH_THRESHOLD: 0.05,
            AMPLIFICATION: 50,
            SILENCE_DELAY_MS: 1000,          // [FIX] à¹€à¸žà¸´à¹ˆà¸¡à¸ˆà¸²à¸ 800 à¹€à¸›à¹‡à¸™ 1000 - à¸£à¸­à¹ƒà¸«à¹‰ user à¸žà¸¹à¸”à¸ˆà¸šà¹à¸™à¹ˆà¹†
            SPEECH_CONFIRMATION_FRAMES: 6,    // [FIX] à¹€à¸žà¸´à¹ˆà¸¡à¸ˆà¸²à¸ 4 à¹€à¸›à¹‡à¸™ 6 - à¸¥à¸”à¸„à¸§à¸²à¸¡à¹„à¸§à¹ƒà¸™à¸à¸²à¸£à¹€à¸£à¸´à¹ˆà¸¡à¸£à¸±à¸šà¹€à¸ªà¸µà¸¢à¸‡
            MIN_BLOB_SIZE_BYTES: 8000,
            smoothingFactor: 0.4,
            MAX_RECORDING_MS: 10000 // 10 à¸§à¸´à¸™à¸²à¸—à¸µ (à¸•à¸²à¸¡à¸—à¸µà¹ˆà¹€à¸£à¸²à¸•à¸±à¹‰à¸‡à¹„à¸§à¹‰)
        };
        Object.assign(this, defaults, options);

        this.smoothedVolume = 0.0;
        this.wasInterrupted = false;
        this.isListening = false;
        this.isSpeaking = false;
        this.silenceTimeout = null;
        this.recordingTimeout = null;
        this.audioChunks = [];
        this.speechFrameCount = 0;

        this.audioContext = audioContext; // ðŸ‘ˆ [à¹à¸à¹‰à¹„à¸‚] à¹ƒà¸Šà¹‰ Context à¸—à¸µà¹ˆà¸£à¸±à¸šà¹€à¸‚à¹‰à¸²à¸¡à¸²
        this.mediaStream = null;
        this.mediaRecorder = null;
        this.analyser = null;
        this.dataArray = null;
    }

    _getAudioContext() {
        // ðŸ‘ˆ [à¸¥à¸š] à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸™à¸µà¹‰à¹„à¸¡à¹ˆà¸ˆà¸³à¹€à¸›à¹‡à¸™à¸­à¸µà¸à¸•à¹ˆà¸­à¹„à¸› à¹€à¸žà¸£à¸²à¸°à¹€à¸£à¸²à¸£à¸±à¸š audioContext à¸ˆà¸²à¸ constructor à¹à¸¥à¹‰à¸§
        // à¹€à¸£à¸²à¸ˆà¸°à¸›à¸¥à¹ˆà¸­à¸¢à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™ start() à¹ƒà¸«à¹‰à¹ƒà¸Šà¹‰ this.audioContext à¹‚à¸”à¸¢à¸•à¸£à¸‡
        return this.audioContext;
    }

    async start() {
        if (this.isListening) return;

        // ðŸ‘ˆ [à¹à¸à¹‰à¹„à¸‚] à¹ƒà¸Šà¹‰ this.audioContext à¹‚à¸”à¸¢à¸•à¸£à¸‡
        const audioContext = this.audioContext;
        if (audioContext.state === 'suspended') {
            await audioContext.resume();
        }

        try {
            this.mediaStream = await navigator.mediaDevices.getUserMedia({
                audio: {
                    noiseSuppression: true,
                    echoCancellation: true,
                    autoGainControl: true,
                }
            });

            const source = audioContext.createMediaStreamSource(this.mediaStream);
            this.analyser = audioContext.createAnalyser();
            this.analyser.fftSize = 256;
            source.connect(this.analyser);
            this.dataArray = new Uint8Array(this.analyser.frequencyBinCount);

            // [à¹à¸à¹‰à¹„à¸‚] à¸à¸²à¸£à¸±à¸™à¸•à¸µ MimeType
            const mimeTypes = [
                'audio/webm;codecs=opus', 'audio/ogg;codecs=opus', 'audio/webm'
            ];
            const supportedMimeType = mimeTypes.find(type => MediaRecorder.isTypeSupported(type));

            if (!supportedMimeType) {
                console.error("VAD: à¹„à¸¡à¹ˆà¸¡à¸µ MimeType à¸—à¸µà¹ˆà¸£à¸­à¸‡à¸£à¸±à¸š (webm/ogg) à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸­à¸±à¸”à¹€à¸ªà¸µà¸¢à¸‡");
                this.callbacks.onStatusUpdate("à¹€à¸šà¸£à¸²à¸§à¹Œà¹€à¸‹à¸­à¸£à¹Œà¹„à¸¡à¹ˆà¸£à¸­à¸‡à¸£à¸±à¸šà¸à¸²à¸£à¸­à¸±à¸”à¹€à¸ªà¸µà¸¢à¸‡");
                return;
            }

            console.log("VAD: Using supported mimeType:", supportedMimeType);
            const options = { mimeType: supportedMimeType, audioBitsPerSecond: 128000 };
            this.mediaRecorder = new MediaRecorder(this.mediaStream, options);


            this.mediaRecorder.ondataavailable = (event) => {
                if (event.data.size > 0) this.audioChunks.push(event.data);
            };

            this.mediaRecorder.onstop = () => {
                if (this.wasInterrupted) {
                    this.audioChunks = [];
                    this.wasInterrupted = false;
                    return;
                }
                const audioBlob = new Blob(this.audioChunks, { type: 'audio/webm' });
                this.audioChunks = [];

                if (audioBlob.size > this.MIN_BLOB_SIZE_BYTES) {
                    this.callbacks.onSpeechEnd(audioBlob);
                } else {
                    console.log(`ðŸŽ¤ VAD: Discarding audio, too small (${audioBlob.size} bytes).`);
                }
                this.callbacks.onStatusUpdate("à¸à¸³à¸¥à¸±à¸‡à¸Ÿà¸±à¸‡...");
            };

            this.isListening = true;
            this.smoothedVolume = 0.0;
            this.speechFrameCount = 0;
            this.callbacks.onStatusUpdate("à¸à¸³à¸¥à¸±à¸‡à¸Ÿà¸±à¸‡...");
            this._runDetectionLoop();

            // [à¹€à¸žà¸´à¹ˆà¸¡] à¹€à¸£à¸´à¹ˆà¸¡à¸ˆà¸±à¸šà¹€à¸§à¸¥à¸²à¸­à¸±à¸”à¸ªà¸¹à¸‡à¸ªà¸¸à¸”
            this.recordingTimeout = setTimeout(() => {
                console.warn(`VAD: Max recording time reached (${this.MAX_RECORDING_MS / 1000}s). Forcing stop.`);
                this.stop(false);
            }, this.MAX_RECORDING_MS);

        } catch (err) {
            console.error("VAD: Microphone access error:", err);
            this.callbacks.onStatusUpdate("à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¹€à¸‚à¹‰à¸²à¸–à¸¶à¸‡à¹„à¸¡à¹‚à¸„à¸£à¹‚à¸Ÿà¸™");
        }
    }

    stop(interrupted = false) {
        if (!this.isListening) return;

        this.wasInterrupted = interrupted;
        this.isListening = false;

        if (this.mediaRecorder && this.mediaRecorder.state === 'recording') {
            this.mediaRecorder.stop();
        }
        this.mediaStream?.getTracks().forEach(track => track.stop());
        this.mediaStream = null;
        clearTimeout(this.silenceTimeout);
        this.silenceTimeout = null;

        clearTimeout(this.recordingTimeout); // [à¹€à¸žà¸´à¹ˆà¸¡] à¹€à¸„à¸¥à¸µà¸¢à¸£à¹Œà¸•à¸±à¸§à¸ˆà¸±à¸šà¹€à¸§à¸¥à¸²à¸ªà¸¹à¸‡à¸ªà¸¸à¸”
        this.recordingTimeout = null;      // [à¹€à¸žà¸´à¹ˆà¸¡]

        console.log("VAD: Stopped.");
        this.callbacks.onStatusUpdate("à¸«à¸¢à¸¸à¸”à¸—à¸³à¸‡à¸²à¸™");
    }

    _runDetectionLoop() {
        if (!this.isListening) return;
        requestAnimationFrame(() => this._runDetectionLoop());

        this.analyser.getByteTimeDomainData(this.dataArray);
        let sumSquares = 0.0;
        for (const amplitude of this.dataArray) {
            const normalizedAmplitude = (amplitude / 128.0) - 1.0;
            sumSquares += normalizedAmplitude * normalizedAmplitude;
        }
        let rawVolume = Math.sqrt(sumSquares / this.dataArray.length);

        if (rawVolume < this.NOISE_FLOOR) rawVolume = 0;

        const amplifiedVolume = rawVolume * this.AMPLIFICATION;
        this.smoothedVolume = this.smoothedVolume * this.smoothingFactor + amplifiedVolume * (1 - this.smoothingFactor);

        if (this.smoothedVolume > this.SPEECH_THRESHOLD) {
            this.speechFrameCount++;
            if (this.speechFrameCount >= this.SPEECH_CONFIRMATION_FRAMES) {
                if (!this.isSpeaking) {
                    this.isSpeaking = true;
                    if (this.mediaRecorder.state === 'inactive') this.mediaRecorder.start();
                    this.callbacks.onStatusUpdate("à¸£à¸±à¸šà¸Ÿà¸±à¸‡à¸­à¸¢à¸¹à¹ˆ...");
                }
                clearTimeout(this.silenceTimeout);
                this.silenceTimeout = null;
            }
        } else {
            this.speechFrameCount = 0;
            if (this.isSpeaking && this.silenceTimeout === null) {
                this.silenceTimeout = setTimeout(() => {
                    if (this.mediaRecorder.state === 'recording') {
                        this.mediaRecorder.stop();
                    }
                    this.isSpeaking = false;
                    this.silenceTimeout = null;
                }, this.SILENCE_DELAY_MS);
            }
        }
    }
}