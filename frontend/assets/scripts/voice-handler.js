class VoiceHandler {
    /**
     * @param {AudioContext} audioContext - [à¹à¸à¹‰à¹„à¸‚] à¸£à¸±à¸š AudioContext à¸—à¸µà¹ˆà¸ªà¸£à¹‰à¸²à¸‡à¸ˆà¸²à¸à¸‚à¹‰à¸²à¸‡à¸™à¸­à¸
     * @param {object} callbacks - à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™ Callback à¸•à¹ˆà¸²à¸‡à¹†
     * @param {function} callbacks.onStatusUpdate
     * @param {function} callbacks.onSpeechEnd
     * @param {object} options - à¸à¸²à¸£à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² VAD
     */
    constructor(audioContext, callbacks, options = {}) { // ðŸ‘ˆ [à¹à¸à¹‰à¹„à¸‚] à¹€à¸žà¸´à¹ˆà¸¡ audioContext
        if (!audioContext) {
            throw new Error("VoiceHandler requires a valid AudioContext to be provided.");
        }

        this.callbacks = { onStatusUpdate: () => { }, onSpeechEnd: () => { }, ...callbacks };

        const defaults = {
            NOISE_FLOOR: 0.003,               // à¸•à¸±à¸”à¹€à¸ªà¸µà¸¢à¸‡ noise à¸•à¹ˆà¸³à¸¡à¸²à¸
            SPEECH_THRESHOLD: 0.35,           // [FIX] à¸¥à¸”à¸ˆà¸²à¸ 0.5 â†’ 0.35 (à¹ƒà¸à¸¥à¹‰ ambient ~0.28 à¸¡à¸²à¸à¸‚à¸¶à¹‰à¸™)
            AMPLIFICATION: 60,                // [FIX] à¹€à¸žà¸´à¹ˆà¸¡à¸ˆà¸²à¸ 50 â†’ 60
            SILENCE_DELAY_MS: 1500,           // à¸£à¸­à¹ƒà¸«à¹‰ user à¸žà¸¹à¸”à¸ˆà¸šà¹à¸™à¹ˆà¹†
            SPEECH_CONFIRMATION_FRAMES: 3,    // à¹€à¸£à¸´à¹ˆà¸¡à¸£à¸±à¸šà¸£à¸§à¸”à¹€à¸£à¹‡à¸§
            MIN_BLOB_SIZE_BYTES: 5000,        // à¸¢à¸­à¸¡à¸£à¸±à¸šà¹„à¸Ÿà¸¥à¹Œà¹€à¸¥à¹‡à¸à¸à¸§à¹ˆà¸²
            smoothingFactor: 0.2,             // à¸•à¸­à¸šà¸ªà¸™à¸­à¸‡à¹€à¸£à¹‡à¸§
            MAX_RECORDING_MS: 15000           // 15 à¸§à¸´à¸™à¸²à¸—à¸µ
        };
        Object.assign(this, defaults, options);

        this.smoothedVolume = 0.0;
        this.wasInterrupted = false;
        this.isListening = false;
        this.isSpeaking = false;
        this.silenceTimeout = null;
        this.recordingTimeout = null;
        this.audioChunks = [];
        this.speechFrameCount = 0;

        this.audioContext = audioContext; // ðŸ‘ˆ [à¹à¸à¹‰à¹„à¸‚] à¹ƒà¸Šà¹‰ Context à¸—à¸µà¹ˆà¸£à¸±à¸šà¹€à¸‚à¹‰à¸²à¸¡à¸²
        this.mediaStream = null;
        this.mediaRecorder = null;
        this.analyser = null;
        this.dataArray = null;
    }

    _getAudioContext() {
        // ðŸ‘ˆ [à¸¥à¸š] à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸™à¸µà¹‰à¹„à¸¡à¹ˆà¸ˆà¸³à¹€à¸›à¹‡à¸™à¸­à¸µà¸à¸•à¹ˆà¸­à¹„à¸› à¹€à¸žà¸£à¸²à¸°à¹€à¸£à¸²à¸£à¸±à¸š audioContext à¸ˆà¸²à¸ constructor à¹à¸¥à¹‰à¸§
        // à¹€à¸£à¸²à¸ˆà¸°à¸›à¸¥à¹ˆà¸­à¸¢à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™ start() à¹ƒà¸«à¹‰à¹ƒà¸Šà¹‰ this.audioContext à¹‚à¸”à¸¢à¸•à¸£à¸‡
        return this.audioContext;
    }

    async start() {
        console.log('ðŸŽ™ï¸ [VoiceHandler.start] Called, isListening:', this.isListening);
        if (this.isListening) {
            console.log('ðŸŽ™ï¸ [VoiceHandler.start] Already listening, returning');
            return;
        }

        // ðŸ‘ˆ [à¹à¸à¹‰à¹„à¸‚] à¹ƒà¸Šà¹‰ this.audioContext à¹‚à¸”à¸¢à¸•à¸£à¸‡
        const audioContext = this.audioContext;
        console.log('ðŸŽ™ï¸ [VoiceHandler.start] AudioContext state:', audioContext.state);
        if (audioContext.state === 'suspended') {
            console.log('ðŸŽ™ï¸ [VoiceHandler.start] Resuming AudioContext...');
            await audioContext.resume();
        }

        try {
            console.log('ðŸŽ™ï¸ [VoiceHandler.start] Requesting microphone access...');
            this.mediaStream = await navigator.mediaDevices.getUserMedia({
                audio: {
                    noiseSuppression: true,
                    echoCancellation: true,
                    autoGainControl: true,
                }
            });
            console.log('ðŸŽ™ï¸ [VoiceHandler.start] Microphone access granted!');

            // ðŸ” [DEBUG] à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š audio tracks
            const audioTracks = this.mediaStream.getAudioTracks();
            console.log('ðŸ” [DEBUG] Audio tracks:', audioTracks.length);
            audioTracks.forEach((track, i) => {
                console.log(`ðŸ” [DEBUG] Track ${i}: ${track.label}, enabled: ${track.enabled}, muted: ${track.muted}, readyState: ${track.readyState}`);
            });

            const source = audioContext.createMediaStreamSource(this.mediaStream);
            this.analyser = audioContext.createAnalyser();
            this.analyser.fftSize = 256;
            source.connect(this.analyser);
            this.dataArray = new Uint8Array(this.analyser.frequencyBinCount);

            console.log('ðŸ” [DEBUG] Analyser created, frequencyBinCount:', this.analyser.frequencyBinCount);

            // [à¹à¸à¹‰à¹„à¸‚] à¸à¸²à¸£à¸±à¸™à¸•à¸µ MimeType
            const mimeTypes = [
                'audio/webm;codecs=opus', 'audio/ogg;codecs=opus', 'audio/webm'
            ];
            const supportedMimeType = mimeTypes.find(type => MediaRecorder.isTypeSupported(type));

            if (!supportedMimeType) {
                console.error("VAD: à¹„à¸¡à¹ˆà¸¡à¸µ MimeType à¸—à¸µà¹ˆà¸£à¸­à¸‡à¸£à¸±à¸š (webm/ogg) à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸­à¸±à¸”à¹€à¸ªà¸µà¸¢à¸‡");
                this.callbacks.onStatusUpdate("à¹€à¸šà¸£à¸²à¸§à¹Œà¹€à¸‹à¸­à¸£à¹Œà¹„à¸¡à¹ˆà¸£à¸­à¸‡à¸£à¸±à¸šà¸à¸²à¸£à¸­à¸±à¸”à¹€à¸ªà¸µà¸¢à¸‡");
                return;
            }

            console.log("ðŸŽ™ï¸ [VoiceHandler.start] Using mimeType:", supportedMimeType);
            const options = { mimeType: supportedMimeType, audioBitsPerSecond: 128000 };
            this.mediaRecorder = new MediaRecorder(this.mediaStream, options);


            this.mediaRecorder.ondataavailable = (event) => {
                if (event.data.size > 0) this.audioChunks.push(event.data);
            };

            this.mediaRecorder.onstop = () => {
                console.log('ðŸŽ™ï¸ [VoiceHandler] MediaRecorder stopped');
                if (this.wasInterrupted) {
                    this.audioChunks = [];
                    this.wasInterrupted = false;
                    return;
                }
                const audioBlob = new Blob(this.audioChunks, { type: 'audio/webm' });
                this.audioChunks = [];

                console.log('ðŸŽ™ï¸ [VoiceHandler] Audio blob size:', audioBlob.size);
                if (audioBlob.size > this.MIN_BLOB_SIZE_BYTES) {
                    this.callbacks.onSpeechEnd(audioBlob);
                } else {
                    console.log(`ðŸŽ¤ VAD: Discarding audio, too small (${audioBlob.size} bytes).`);
                }
                this.callbacks.onStatusUpdate("à¸à¸³à¸¥à¸±à¸‡à¸Ÿà¸±à¸‡...");
            };

            this.isListening = true;
            this.smoothedVolume = 0.0;
            this.speechFrameCount = 0;
            this.callbacks.onStatusUpdate("à¸à¸³à¸¥à¸±à¸‡à¸Ÿà¸±à¸‡...");
            console.log('ðŸŸ¢ [VoiceHandler.start] Now listening! Starting detection loop...');
            this._runDetectionLoop();

            // [à¹€à¸žà¸´à¹ˆà¸¡] à¹€à¸£à¸´à¹ˆà¸¡à¸ˆà¸±à¸šà¹€à¸§à¸¥à¸²à¸­à¸±à¸”à¸ªà¸¹à¸‡à¸ªà¸¸à¸”
            this.recordingTimeout = setTimeout(() => {
                console.warn(`VAD: Max recording time reached (${this.MAX_RECORDING_MS / 1000}s). Forcing stop.`);
                this.stop(false);
            }, this.MAX_RECORDING_MS);

        } catch (err) {
            console.error("ðŸ”´ [VoiceHandler.start] Microphone access error:", err);
            this.callbacks.onStatusUpdate("à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¹€à¸‚à¹‰à¸²à¸–à¸¶à¸‡à¹„à¸¡à¹‚à¸„à¸£à¹‚à¸Ÿà¸™");
        }
    }

    stop(interrupted = false) {
        if (!this.isListening) return;

        this.wasInterrupted = interrupted;
        this.isListening = false;

        if (this.mediaRecorder && this.mediaRecorder.state === 'recording') {
            this.mediaRecorder.stop();
        }
        this.mediaStream?.getTracks().forEach(track => track.stop());
        this.mediaStream = null;
        clearTimeout(this.silenceTimeout);
        this.silenceTimeout = null;

        clearTimeout(this.recordingTimeout); // [à¹€à¸žà¸´à¹ˆà¸¡] à¹€à¸„à¸¥à¸µà¸¢à¸£à¹Œà¸•à¸±à¸§à¸ˆà¸±à¸šà¹€à¸§à¸¥à¸²à¸ªà¸¹à¸‡à¸ªà¸¸à¸”
        this.recordingTimeout = null;      // [à¹€à¸žà¸´à¹ˆà¸¡]

        console.log("VAD: Stopped.");
        this.callbacks.onStatusUpdate("à¸«à¸¢à¸¸à¸”à¸—à¸³à¸‡à¸²à¸™");
    }

    _runDetectionLoop() {
        if (!this.isListening) return;
        requestAnimationFrame(() => this._runDetectionLoop());

        this.analyser.getByteTimeDomainData(this.dataArray);
        let sumSquares = 0.0;
        for (const amplitude of this.dataArray) {
            const normalizedAmplitude = (amplitude / 128.0) - 1.0;
            sumSquares += normalizedAmplitude * normalizedAmplitude;
        }
        let rawVolume = Math.sqrt(sumSquares / this.dataArray.length);

        if (rawVolume < this.NOISE_FLOOR) rawVolume = 0;

        const amplifiedVolume = rawVolume * this.AMPLIFICATION;
        this.smoothedVolume = this.smoothedVolume * this.smoothingFactor + amplifiedVolume * (1 - this.smoothingFactor);

        // ðŸ”Š [DEBUG] à¹à¸ªà¸”à¸‡à¸£à¸°à¸”à¸±à¸šà¹€à¸ªà¸µà¸¢à¸‡à¸—à¸¸à¸ 60 frames (~1 à¸§à¸´à¸™à¸²à¸—à¸µ)
        if (!this._debugFrameCount) this._debugFrameCount = 0;
        this._debugFrameCount++;
        if (this._debugFrameCount % 60 === 0) {
            // à¹à¸ªà¸”à¸‡ raw data à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡ 10 à¸•à¸±à¸§à¹à¸£à¸
            const sampleData = Array.from(this.dataArray.slice(0, 10));
            const rawVolumeBeforeFloor = Math.sqrt(sumSquares / this.dataArray.length);
            console.log(`ðŸ”Š [VAD] rawVolume: ${rawVolumeBeforeFloor.toFixed(6)} | amplified: ${amplifiedVolume.toFixed(4)} | smoothed: ${this.smoothedVolume.toFixed(4)} | threshold: ${this.SPEECH_THRESHOLD}`);
            console.log(`ðŸ”Š [VAD] Raw data sample (first 10):`, sampleData, `(128 = silence)`);
        }

        if (this.smoothedVolume > this.SPEECH_THRESHOLD) {
            this.speechFrameCount++;
            if (this.speechFrameCount >= this.SPEECH_CONFIRMATION_FRAMES) {
                if (!this.isSpeaking) {
                    this.isSpeaking = true;
                    console.log('ðŸŸ¢ [VAD] Speech DETECTED! Starting recording...');
                    if (this.mediaRecorder.state === 'inactive') this.mediaRecorder.start();
                    this.callbacks.onStatusUpdate("à¸£à¸±à¸šà¸Ÿà¸±à¸‡à¸­à¸¢à¸¹à¹ˆ...");
                }
                clearTimeout(this.silenceTimeout);
                this.silenceTimeout = null;
            }
        } else {
            this.speechFrameCount = 0;
            if (this.isSpeaking && this.silenceTimeout === null) {
                this.silenceTimeout = setTimeout(() => {
                    console.log('ðŸ”´ [VAD] Silence detected, stopping recording...');
                    if (this.mediaRecorder.state === 'recording') {
                        this.mediaRecorder.stop();
                    }
                    this.isSpeaking = false;
                    this.silenceTimeout = null;
                }, this.SILENCE_DELAY_MS);
            }
        }
    }
}