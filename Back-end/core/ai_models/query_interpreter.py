import logging
import json
import asyncio
from groq import AsyncGroq
from typing import Dict, Any, Optional, List
from .key_manager import groq_key_manager
from core.config import settings

class QueryInterpreter:
    _PRE_CORRECTION_MAP = {
        "‡∏´‡∏ß‡∏±‡∏î‡∏î‡∏µ‡∏Ñ‡∏±‡∏ö": "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ",
        "‡∏î‡∏µ‡∏Ñ‡∏±‡∏ö": "‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö",
        "‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ô": "‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì",
        "‡πÄ‡∏õ‡∏¥‡∏î‡πÄ‡∏û‡∏á": "‡πÄ‡∏õ‡∏¥‡∏î‡πÄ‡∏û‡∏•‡∏á",
        "‡∏ß‡∏±‡∏î‡∏û‡∏π‡∏°‡∏¥‡∏ô": "‡∏ß‡∏±‡∏î‡∏†‡∏π‡∏°‡∏¥‡∏ô‡∏ó‡∏£‡πå",
        "‡∏ß‡∏±‡∏î‡∏û‡∏π‡∏°‡∏¥‡∏ô‡∏ó‡∏£‡πå": "‡∏ß‡∏±‡∏î‡∏†‡∏π‡∏°‡∏¥‡∏ô‡∏ó‡∏£‡πå",
        "‡∏ß‡∏±‡∏î‡∏†‡∏π‡∏°‡∏¥‡∏ô": "‡∏ß‡∏±‡∏î‡∏†‡∏π‡∏°‡∏¥‡∏ô‡∏ó‡∏£‡πå",
        "‡∏ß‡∏±‡∏î‡πÅ‡∏ä‡πà‡πÅ‡∏´‡πâ‡∏á": "‡∏ß‡∏±‡∏î‡∏û‡∏£‡∏∞‡∏ò‡∏≤‡∏ï‡∏∏‡πÅ‡∏ä‡πà‡πÅ‡∏´‡πâ‡∏á",
        "‡∏û‡∏£‡∏∞‡∏ó‡∏≤‡∏î‡πÅ‡∏ä‡πà‡πÅ‡∏´‡πâ‡∏á": "‡∏û‡∏£‡∏∞‡∏ò‡∏≤‡∏ï‡∏∏‡πÅ‡∏ä‡πà‡πÅ‡∏´‡πâ‡∏á",
        "‡∏î‡∏≠‡∏¢‡πÄ‡∏™‡∏°‡∏≠‡πÄ‡∏î‡∏≤": "‡∏î‡∏≠‡∏¢‡πÄ‡∏™‡∏°‡∏≠‡∏î‡∏≤‡∏ß",
        "‡πÄ‡∏™‡∏°‡∏≠‡∏î‡∏≤‡∏ß": "‡∏î‡∏≠‡∏¢‡πÄ‡∏™‡∏°‡∏≠‡∏î‡∏≤‡∏ß",
        "‡∏õ‡∏π‡πà‡∏°‡πà‡∏≤‡∏ô‡∏¢‡πà‡∏≤‡∏°‡πà‡∏≤‡∏ô": "‡∏õ‡∏π‡πà‡∏°‡πà‡∏≤‡∏ô‡∏¢‡πà‡∏≤‡∏°‡πà‡∏≤‡∏ô",
    }

    _CANNED_RESPONSES = {
        "GREETING": {"intent": "SMALL_TALK", "entity": None, "is_complex": False, "sub_queries": [""]},
        "THANKS": {"intent": "SMALL_TALK", "entity": None, "is_complex": False, "sub_queries": [""]},
        "FAREWELL": {"intent": "SMALL_TALK", "entity": None, "is_complex": False, "sub_queries": [""]}
    }
    _QUERY_MAP = {
        "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ": "GREETING", "‡∏´‡∏ß‡∏±‡∏î‡∏î‡∏µ": "GREETING", "‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö": "GREETING", "‡∏î‡∏µ‡∏Ñ‡πà‡∏∞": "GREETING",
        "‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì": "THANKS", "‡∏Ç‡∏≠‡∏ö‡πÉ‡∏à": "THANKS", "‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏£‡∏±‡∏ö": "THANKS", "‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡πà‡∏∞": "THANKS",
        "‡∏•‡∏≤‡∏Å‡πà‡∏≠‡∏ô": "FAREWELL", "‡πÑ‡∏õ‡πÅ‡∏•‡πâ‡∏ß‡∏ô‡∏∞": "FAREWELL", "‡∏ö‡πä‡∏≤‡∏¢‡∏ö‡∏≤‡∏¢": "FAREWELL",
    }

    _ENTITY_ALIASES = {
        "‡∏ß‡∏±‡∏î‡∏†‡∏π‡∏°‡∏¥‡∏ô‡∏ó‡∏£‡πå": "‡∏ß‡∏±‡∏î‡∏†‡∏π‡∏°‡∏¥‡∏ô‡∏ó‡∏£‡πå",
        "‡∏õ‡∏π‡πà‡∏°‡πà‡∏≤‡∏ô‡∏¢‡πà‡∏≤‡∏°‡πà‡∏≤‡∏ô": "‡∏†‡∏≤‡∏û‡∏Å‡∏£‡∏∞‡∏ã‡∏¥‡∏ö‡∏£‡∏±‡∏Å‡∏ö‡∏±‡∏ô‡∏•‡∏∑‡∏≠‡πÇ‡∏•‡∏Å",
        "‡∏†‡∏≤‡∏û‡∏Å‡∏£‡∏∞‡∏ã‡∏¥‡∏ö‡∏£‡∏±‡∏Å": "‡∏†‡∏≤‡∏û‡∏Å‡∏£‡∏∞‡∏ã‡∏¥‡∏ö‡∏£‡∏±‡∏Å‡∏ö‡∏±‡∏ô‡∏•‡∏∑‡∏≠‡πÇ‡∏•‡∏Å",
        "‡∏†‡∏≤‡∏û‡∏Å‡∏£‡∏∞‡∏ã‡∏¥‡∏ö‡∏£‡∏±‡∏Å‡∏ö‡∏±‡∏ô‡∏•‡∏∑‡∏≠‡πÇ‡∏•‡∏Å": "‡∏†‡∏≤‡∏û‡∏Å‡∏£‡∏∞‡∏ã‡∏¥‡∏ö‡∏£‡∏±‡∏Å‡∏ö‡∏±‡∏ô‡∏•‡∏∑‡∏≠‡πÇ‡∏•‡∏Å",
        "‡∏î‡∏≠‡∏¢‡πÄ‡∏™‡∏°‡∏≠‡∏î‡∏≤‡∏ß": "‡∏î‡∏≠‡∏¢‡πÄ‡∏™‡∏°‡∏≠‡∏î‡∏≤‡∏ß",
        "‡∏ß‡∏±‡∏î‡∏û‡∏£‡∏∞‡∏ò‡∏≤‡∏ï‡∏∏‡πÅ‡∏ä‡πà‡πÅ‡∏´‡πâ‡∏á": "‡∏ß‡∏±‡∏î‡∏û‡∏£‡∏∞‡∏ò‡∏≤‡∏ï‡∏∏‡πÅ‡∏ä‡πà‡πÅ‡∏´‡πâ‡∏á",
    }
    _INTERNAL_KNOWLEDGE_BASE = {
        "‡∏ß‡∏±‡∏î‡∏†‡∏π‡∏°‡∏¥‡∏ô‡∏ó‡∏£‡πå": "‡∏ß‡∏±‡∏î‡∏†‡∏π‡∏°‡∏¥‡∏ô‡∏ó‡∏£‡πå‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏±‡∏î‡∏´‡∏•‡∏ß‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ô‡πà‡∏≤‡∏ô ‡∏°‡∏µ‡∏à‡∏∏‡∏î‡πÄ‡∏î‡πà‡∏ô‡∏Ñ‡∏∑‡∏≠‡∏û‡∏£‡∏∞‡∏≠‡∏∏‡πÇ‡∏ö‡∏™‡∏ñ‡∏à‡∏ï‡∏∏‡∏£‡∏°‡∏∏‡∏Ç‡πÅ‡∏•‡∏∞‡∏†‡∏≤‡∏û‡∏à‡∏¥‡∏ï‡∏£‡∏Å‡∏£‡∏£‡∏°‡∏ù‡∏≤‡∏ú‡∏ô‡∏±‡∏á‡∏õ‡∏π‡πà‡∏°‡πà‡∏≤‡∏ô‡∏¢‡πà‡∏≤‡∏°‡πà‡∏≤‡∏ô ‡∏´‡∏£‡∏∑‡∏≠‡∏†‡∏≤‡∏û‡∏Å‡∏£‡∏∞‡∏ã‡∏¥‡∏ö‡∏£‡∏±‡∏Å‡∏ö‡∏±‡∏ô‡∏•‡∏∑‡∏≠‡πÇ‡∏•‡∏Å‡∏≠‡∏±‡∏ô‡πÇ‡∏î‡πà‡∏á‡∏î‡∏±‡∏á‡∏Ñ‡∏£‡∏±‡∏ö",
        "‡∏†‡∏≤‡∏û‡∏Å‡∏£‡∏∞‡∏ã‡∏¥‡∏ö‡∏£‡∏±‡∏Å‡∏ö‡∏±‡∏ô‡∏•‡∏∑‡∏≠‡πÇ‡∏•‡∏Å": "‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏û‡∏à‡∏¥‡∏ï‡∏£‡∏Å‡∏£‡∏£‡∏°‡∏ù‡∏≤‡∏ú‡∏ô‡∏±‡∏á‡∏≠‡∏±‡∏ô‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡∏ß‡∏¥‡∏´‡∏≤‡∏£‡∏Ç‡∏≠‡∏á‡∏ß‡∏±‡∏î‡∏†‡∏π‡∏°‡∏¥‡∏ô‡∏ó‡∏£‡πå ‡∏ß‡∏≤‡∏î‡πÇ‡∏î‡∏¢‡∏´‡∏ô‡∏≤‡∏ô‡∏ö‡∏±‡∏ß‡∏ú‡∏±‡∏ô ‡πÅ‡∏™‡∏î‡∏á‡∏†‡∏≤‡∏û‡∏ä‡∏≤‡∏¢‡∏´‡∏ç‡∏¥‡∏á‡∏Ñ‡∏π‡πà‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Å‡∏£‡∏∞‡∏ã‡∏¥‡∏ö‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏Å‡∏±‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÉ‡∏Å‡∏•‡πâ‡∏ä‡∏¥‡∏î ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏±‡∏Å‡∏ó‡∏µ‡πà‡πÇ‡∏£‡πÅ‡∏°‡∏ô‡∏ï‡∏¥‡∏Å‡∏Ñ‡∏£‡∏±‡∏ö",
        "‡∏î‡∏≠‡∏¢‡πÄ‡∏™‡∏°‡∏≠‡∏î‡∏≤‡∏ß": "‡∏î‡∏≠‡∏¢‡πÄ‡∏™‡∏°‡∏≠‡∏î‡∏≤‡∏ß‡πÄ‡∏õ‡πá‡∏ô‡∏à‡∏∏‡∏î‡∏ä‡∏°‡∏ß‡∏¥‡∏ß‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏á‡πÄ‡∏ï‡πá‡∏ô‡∏ó‡πå‡∏¢‡∏≠‡∏î‡∏ô‡∏¥‡∏¢‡∏°‡πÉ‡∏ô‡∏≠‡∏∏‡∏ó‡∏¢‡∏≤‡∏ô‡πÅ‡∏´‡πà‡∏á‡∏ä‡∏≤‡∏ï‡∏¥‡∏®‡∏£‡∏µ‡∏ô‡πà‡∏≤‡∏ô ‡∏Ç‡∏∂‡πâ‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ä‡∏°‡∏ó‡∏∞‡πÄ‡∏•‡∏´‡∏°‡∏≠‡∏Å‡πÉ‡∏ô‡∏ï‡∏≠‡∏ô‡πÄ‡∏ä‡πâ‡∏≤‡πÅ‡∏•‡∏∞‡∏î‡∏π‡∏î‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡∏™‡∏ß‡∏¢‡∏á‡∏≤‡∏°‡πÄ‡∏ï‡πá‡∏°‡∏ó‡πâ‡∏≠‡∏á‡∏ü‡πâ‡∏≤‡πÉ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏•‡∏≤‡∏á‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡∏£‡∏±‡∏ö",
        "‡∏ß‡∏±‡∏î‡∏û‡∏£‡∏∞‡∏ò‡∏≤‡∏ï‡∏∏‡πÅ‡∏ä‡πà‡πÅ‡∏´‡πâ‡∏á": "‡∏ß‡∏±‡∏î‡∏û‡∏£‡∏∞‡∏ò‡∏≤‡∏ï‡∏∏‡πÅ‡∏ä‡πà‡πÅ‡∏´‡πâ‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏û‡∏£‡∏∞‡∏ò‡∏≤‡∏ï‡∏∏‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡∏ô‡πà‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏û‡∏£‡∏∞‡∏ò‡∏≤‡∏ï‡∏∏‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡∏õ‡∏µ‡πÄ‡∏ñ‡∏≤‡∏∞ ‡∏°‡∏µ‡∏≠‡∏á‡∏Ñ‡πå‡∏û‡∏£‡∏∞‡∏ò‡∏≤‡∏ï‡∏∏‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏µ‡∏ó‡∏≠‡∏á‡∏≠‡∏£‡πà‡∏≤‡∏°‡∏™‡∏ß‡∏¢‡∏á‡∏≤‡∏° ‡πÄ‡∏õ‡πá‡∏ô‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏£‡∏ß‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏®‡∏£‡∏±‡∏ó‡∏ò‡∏≤‡∏Ç‡∏≠‡∏á‡∏ä‡∏≤‡∏ß‡∏ô‡πà‡∏≤‡∏ô‡∏Ñ‡∏£‡∏±‡∏ö"
    }

    def __init__(self):
        self.model_to_use = settings.GROQ_LLAMA_MODEL
        api_key = groq_key_manager.get_key()
        if not api_key:
            logging.error("üö® [Interpreter] CRITICAL: No Groq API key found on init.")
            self.client = None
        else:
            self.client = AsyncGroq(api_key=api_key)
        logging.info(f"üß† Query Interpreter (V6.4 - Pre-correction) initialized with model: {self.model_to_use}")

    async def close(self):
        """Closes the AsyncGroq client."""
        if self.client:
            logging.info("‚è≥ [Interpreter] Closing Groq client...")
            try:
                await self.client.close()
                logging.info("‚úÖ [Interpreter] Groq client closed.")
            except Exception as e:
                logging.error(f"‚ùå Error closing Groq client: {e}")

    def _normalize_query(self, query: str) -> str:
        """Strips whitespace and common Thai particles for matching."""
        q = query.strip().lower()
        particles = ["‡∏Ñ‡∏£‡∏±‡∏ö", "‡∏Ñ‡πà‡∏∞", "‡∏à‡πâ‡∏∞", "‡∏à‡πâ‡∏≤", "‡∏ô‡∏∞", "‡∏´‡∏ô‡πà‡∏≠‡∏¢", "‡∏™‡∏¥"]
        for p in particles:
            if q.endswith(p):
                q = q[:-len(p)].strip()
        return q

    async def _get_groq_response(self, system_prompt: str, user_query: str) -> Optional[str]:
        if not self.client:
            logging.error("‚ùå [Interpreter] Groq client not initialized (No API key).")
            return None
        try:
            chat_completion = await self.client.chat.completions.create(
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_query}
                ],
                model=self.model_to_use,
                temperature=0.0,
                response_format={"type": "json_object"},
            )
            return chat_completion.choices[0].message.content.strip()
        except Exception as e:
            logging.error(f"‚ùå [Interpreter] Groq API Error: {e}", exc_info=True)
            return None

    async def interpret_and_route(self, query: str) -> Dict[str, Any]:
        original_query = query.strip()
        if not original_query:
            return {
                "corrected_query": "", "intent": "SMALL_TALK", "entity": None, 
                "is_complex": False, "sub_queries": [""]
            }

        normalized_for_correction = self._normalize_query(original_query)
        corrected_query = self._PRE_CORRECTION_MAP.get(normalized_for_correction, original_query)
        if corrected_query != original_query:
            logging.info(f"‚úÖ [Interpreter] Pre-corrected: '{original_query}' -> '{corrected_query}'")

        normalized_for_canned = self._normalize_query(corrected_query)
        if normalized_for_canned in self._QUERY_MAP:
            logging.info(f"‚úÖ [Interpreter] Canned response for '{corrected_query}'")
            response_key = self._QUERY_MAP[normalized_for_canned]
            response = self._CANNED_RESPONSES[response_key].copy()
            response["corrected_query"] = corrected_query
            return response

        fallback_result = {
            "corrected_query": corrected_query, "intent": "INFORMATIONAL", "entity": None,
            "is_complex": False, "sub_queries": [corrected_query]
        }
        system_prompt = f"""You are an expert Thai language interpreter, router, and query decomposer for a Nan province tourism guide AI.
Your task is to analyze a noisy user query.
You MUST return a JSON object with exactly these 5 keys: "corrected_query", "intent", "entity", "is_complex", "sub_queries".

1.  **corrected_query**: Reconstruct the query into a clear, natural Thai sentence.
2.  **intent**: Classify into ONE: "INFORMATIONAL", "PLAY_MUSIC", "SYSTEM_COMMAND", "SMALL_TALK".
3.  **entity**: 
    - If "PLAY_MUSIC", extract song/artist.
    - If "SYSTEM_COMMAND", extract app name.
    - If "SMALL_TALK", return null.
    - If "INFORMATIONAL" AND `is_complex: true`, return null.
    - If "INFORMATIONAL" AND `is_complex: false`, extract the SINGLE main topic (e.g., "‡∏ß‡∏±‡∏î‡∏†‡∏π‡∏°‡∏¥‡∏ô‡∏ó‡∏£‡πå", "‡∏õ‡∏π‡πà‡∏°‡πà‡∏≤‡∏ô‡∏¢‡πà‡∏≤‡∏°‡πà‡∏≤‡∏ô", "‡∏î‡∏≠‡∏¢‡πÄ‡∏™‡∏°‡∏≠‡∏î‡∏≤‡∏ß"). If no single topic, return null.
4.  **is_complex**: (Boolean) Is this a complex question that requires multiple separate information retrievals? 
    - `true` if it compares items (A vs B), asks for multiple distinct topics (A and B), or has sequential logic.
    - `false` if it's a simple, single-topic question.
5.  **sub_queries**: (List of strings)
    - If `is_complex: false`, return a list containing only the `corrected_query`.
    - If `is_complex: true`, break the `corrected_query` down into the simplest possible sub-queries.

**EXAMPLES (Crucial):**
* Input: "‡∏ß‡∏±‡∏î ‡∏û‡∏π‡∏°‡∏¥‡∏ô ‡πÑ‡∏õ‡πÑ‡∏á"
  Output: {{"corrected_query": "‡∏ß‡∏±‡∏î‡∏†‡∏π‡∏°‡∏¥‡∏ô‡∏ó‡∏£‡πå‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÑ‡∏á", "intent": "INFORMATIONAL", "entity": "‡∏ß‡∏±‡∏î‡∏†‡∏π‡∏°‡∏¥‡∏ô‡∏ó‡∏£‡πå", "is_complex": false, "sub_queries": ["‡∏ß‡∏±‡∏î‡∏†‡∏π‡∏°‡∏¥‡∏ô‡∏ó‡∏£‡πå‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÑ‡∏á"]}}
* Input: "‡∏Ç‡∏≠‡∏î‡∏π‡∏£‡∏π‡∏õ‡∏õ‡∏π‡πà‡∏°‡πà‡∏≤‡∏ô‡∏¢‡πà‡∏≤‡∏°‡πà‡∏≤‡∏ô"
  Output: {{"corrected_query": "‡∏Ç‡∏≠‡∏î‡∏π‡∏£‡∏π‡∏õ‡∏õ‡∏π‡πà‡∏°‡πà‡∏≤‡∏ô‡∏¢‡πà‡∏≤‡∏°‡πà‡∏≤‡∏ô", "intent": "INFORMATIONAL", "entity": "‡∏õ‡∏π‡πà‡∏°‡πà‡∏≤‡∏ô‡∏¢‡πà‡∏≤‡∏°‡πà‡∏≤‡∏ô", "is_complex": false, "sub_queries": ["‡∏Ç‡∏≠‡∏î‡∏π‡∏£‡∏π‡∏õ‡∏õ‡∏π‡πà‡∏°‡πà‡∏≤‡∏ô‡∏¢‡πà‡∏≤‡∏°‡πà‡∏≤‡∏ô"]}}
* Input: "‡∏ß‡∏±‡∏î‡∏™‡∏ß‡∏¢‡πÜ ‡πÉ‡∏ô‡∏ô‡πà‡∏≤‡∏ô‡∏°‡∏µ‡∏ó‡∏µ‡πà‡πÑ‡∏´‡∏ô‡∏ö‡πâ‡∏≤‡∏á"
  Output: {{"corrected_query": "‡∏ß‡∏±‡∏î‡∏™‡∏ß‡∏¢‡πÜ ‡πÉ‡∏ô‡∏ô‡πà‡∏≤‡∏ô‡∏°‡∏µ‡∏ó‡∏µ‡πà‡πÑ‡∏´‡∏ô‡∏ö‡πâ‡∏≤‡∏á", "intent": "INFORMATIONAL", "entity": null, "is_complex": false, "sub_queries": ["‡∏ß‡∏±‡∏î‡∏™‡∏ß‡∏¢‡πÜ ‡πÉ‡∏ô‡∏ô‡πà‡∏≤‡∏ô‡∏°‡∏µ‡∏ó‡∏µ‡πà‡πÑ‡∏´‡∏ô‡∏ö‡πâ‡∏≤‡∏á"]}}
* Input: "‡πÄ‡∏õ‡∏¥‡∏î‡πÄ‡∏û‡∏á‡πÄ‡∏®‡∏£‡πâ‡∏≤‡πÜ ‡∏ô‡πà‡∏≠‡∏¢"
  Output: {{"corrected_query": "‡πÄ‡∏õ‡∏¥‡∏î‡πÄ‡∏û‡∏•‡∏á‡πÄ‡∏®‡∏£‡πâ‡∏≤‡πÜ ‡∏´‡∏ô‡πà‡∏≠‡∏¢", "intent": "PLAY_MUSIC", "entity": "‡πÄ‡∏û‡∏•‡∏á‡πÄ‡∏®‡∏£‡πâ‡∏≤‡πÜ", "is_complex": false, "sub_queries": ["‡πÄ‡∏õ‡∏¥‡∏î‡πÄ‡∏û‡∏•‡∏á‡πÄ‡∏®‡∏£‡πâ‡∏≤‡πÜ ‡∏´‡∏ô‡πà‡∏≠‡∏¢"]}}
* Input: "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ"
  Output: {{"corrected_query": "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ", "intent": "SMALL_TALK", "entity": null, "is_complex": false, "sub_queries": ["‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ"]}}
* Input: "‡∏ß‡∏±‡∏î‡∏†‡∏π‡∏°‡∏¥‡∏ô‡∏ó‡∏£‡πå‡∏Å‡∏±‡∏ö‡∏ß‡∏±‡∏î‡πÅ‡∏ä‡πà‡πÅ‡∏´‡πâ‡∏á‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡∏¢‡∏±‡∏á‡πÑ‡∏á ‡πÅ‡∏•‡πâ‡∏ß‡∏ß‡∏±‡∏î‡πÑ‡∏´‡∏ô‡∏à‡∏≠‡∏î‡∏£‡∏ñ‡∏á‡πà‡∏≤‡∏¢‡∏Å‡∏ß‡πà‡∏≤?"
  Output: {{"corrected_query": "‡∏ß‡∏±‡∏î‡∏†‡∏π‡∏°‡∏¥‡∏ô‡∏ó‡∏£‡πå‡∏Å‡∏±‡∏ö‡∏ß‡∏±‡∏î‡∏û‡∏£‡∏∞‡∏ò‡∏≤‡∏ï‡∏∏‡πÅ‡∏ä‡πà‡πÅ‡∏´‡πâ‡∏á‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡∏¢‡∏±‡∏á‡πÑ‡∏á ‡πÅ‡∏•‡∏∞‡∏ß‡∏±‡∏î‡πÑ‡∏´‡∏ô‡∏°‡∏µ‡∏ó‡∏µ‡πà‡∏à‡∏≠‡∏î‡∏£‡∏ñ‡∏™‡∏∞‡∏î‡∏ß‡∏Å‡∏Å‡∏ß‡πà‡∏≤?", "intent": "INFORMATIONAL", "entity": null, "is_complex": true, "sub_queries": ["‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö ‡∏ß‡∏±‡∏î‡∏†‡∏π‡∏°‡∏¥‡∏ô‡∏ó‡∏£‡πå ‡πÅ‡∏•‡∏∞ ‡∏ß‡∏±‡∏î‡∏û‡∏£‡∏∞‡∏ò‡∏≤‡∏ï‡∏∏‡πÅ‡∏ä‡πà‡πÅ‡∏´‡πâ‡∏á", "‡∏ó‡∏µ‡πà‡∏à‡∏≠‡∏î‡∏£‡∏ñ ‡∏ß‡∏±‡∏î‡∏†‡∏π‡∏°‡∏¥‡∏ô‡∏ó‡∏£‡πå", "‡∏ó‡∏µ‡πà‡∏à‡∏≠‡∏î‡∏£‡∏ñ ‡∏ß‡∏±‡∏î‡∏û‡∏£‡∏∞‡∏ò‡∏≤‡∏ï‡∏∏‡πÅ‡∏ä‡πà‡πÅ‡∏´‡πâ‡∏á"]}}
* Input: "‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏ô‡πà‡∏≤‡∏ô ‡πÅ‡∏•‡∏∞ ‡∏ä‡∏ô‡πÄ‡∏ú‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à"
  Output: {{"corrected_query": "‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏ô‡πà‡∏≤‡∏ô ‡πÅ‡∏•‡∏∞ ‡∏ä‡∏ô‡πÄ‡∏ú‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à", "intent": "INFORMATIONAL", "entity": null, "is_complex": true, "sub_queries": ["‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ô‡πà‡∏≤‡∏ô", "‡∏ä‡∏ô‡πÄ‡∏ú‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à‡πÉ‡∏ô‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ô‡πà‡∏≤‡∏ô"]}}
"""
        
        logging.info(f"‚úçÔ∏èüß† [Interpreter] Interpreting with LLM: '{corrected_query}'")
        response_str = await self._get_groq_response(system_prompt, corrected_query)
        if not response_str:
            return fallback_result

        try:
            result = json.loads(response_str)
            if not all(k in result for k in ["corrected_query", "intent", "is_complex", "sub_queries"]):
                raise ValueError("Missing required keys")
            if "entity" not in result: result["entity"] = None

            if (result.get("intent") == "INFORMATIONAL" and not result.get("is_complex") and result.get("entity")):
                entity = result["entity"]
                canonical_entity = self._ENTITY_ALIASES.get(entity.strip().lower(), entity.strip().lower())
                
                if canonical_entity in self._INTERNAL_KNOWLEDGE_BASE:
                    logging.info(f"‚úÖ [Interpreter] Found DIRECT ANSWER for entity '{canonical_entity}'")
                    result["direct_answer"] = self._INTERNAL_KNOWLEDGE_BASE[canonical_entity]

            logging.info(f"‚úÖ [Interpreter] LLM Result: {result}")
            return result
        except Exception as e:
            logging.error(f"‚ùå [Interpreter] Failed to parse LLM JSON: {e}. Response: {response_str}")
            return fallback_result