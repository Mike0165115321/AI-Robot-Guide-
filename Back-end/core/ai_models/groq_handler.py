# Back-end/core/ai_models/groq_handler.py
"""
Groq AI Handler (Llama) - ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Fast Mode
‡πÅ‡∏¢‡∏Å‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡∏à‡∏≤‡∏Å llm_handler.py ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏á‡πà‡∏≤‡∏¢
"""

import logging
from typing import List, Dict, Any
from groq import AsyncGroq
from core.config import settings

# Initialize Groq client
groq_client = AsyncGroq(api_key=settings.GROQ_API_KEYS[0] if settings.GROQ_API_KEYS else None)


async def get_groq_response(
    messages: List[Dict[str, str]], 
    model_name: str = None,
    temperature: float = 0.3,
    max_tokens: int = 1024,
    json_mode: bool = False
) -> str:
    """
    ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Å‡∏•‡∏≤‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏Å Groq (Llama)
    """
    if model_name is None:
        model_name = settings.GROQ_LLAMA_MODEL
        
    try:
        kwargs = {
            "model": model_name,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": max_tokens,
        }
        if json_mode:
            kwargs["response_format"] = {"type": "json_object"}

        response = await groq_client.chat.completions.create(**kwargs)
        logging.info(f"‚úÖ [Groq] Response generated successfully")
        return response.choices[0].message.content
        
    except Exception as e:
        logging.error(f"‚ùå [Groq] Error: {e}")
        return f"‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞ ‡∏£‡∏∞‡∏ö‡∏ö Groq ‡∏Ç‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏á‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß ({str(e)[:50]})"


async def get_small_talk_response(user_query: str) -> str:
    """
    ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Small Talk / ‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
    ‡πÉ‡∏ä‡πâ model ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤
    """
    system_prompt = """‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ô‡πâ‡∏≠‡∏á‡∏ô‡πà‡∏≤‡∏ô ‡πÑ‡∏Å‡∏î‡πå‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ô‡πà‡∏≤‡∏ô ‡∏û‡∏π‡∏î‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á

‡∏Å‡∏é‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç:
1. ‡∏ï‡∏≠‡∏ö‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö (2-3 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ)
2. ‡∏≠‡∏¢‡πà‡∏≤‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Å‡∏•‡∏±‡∏ö - ‡πÅ‡∏Ñ‡πà‡∏ï‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£‡πÅ‡∏•‡πâ‡∏ß‡∏à‡∏ö
3. ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ñ‡∏ô‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡πÑ‡∏´‡∏ô ‡πÉ‡∏´‡πâ‡∏ï‡πâ‡∏≠‡∏ô‡∏£‡∏±‡∏ö‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏≠‡∏ö‡∏≠‡∏∏‡πà‡∏ô
4. ‡∏≠‡∏¢‡πà‡∏≤‡∏ñ‡∏≤‡∏°‡∏ß‡πà‡∏≤ "‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡πÑ‡∏´‡∏ô" ‡∏´‡∏£‡∏∑‡∏≠ "‡∏™‡∏ô‡πÉ‡∏à‡∏≠‡∏∞‡πÑ‡∏£" ‡∏ã‡πâ‡∏≥‡∏≠‡∏µ‡∏Å

‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏î‡∏µ:
- "‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡∏à‡∏µ‡∏ô‡∏Ñ‡∏£‡∏±‡∏ö" ‚Üí "‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ï‡πâ‡∏≠‡∏ô‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏∞! ‡∏ô‡πà‡∏≤‡∏ô‡∏°‡∏µ‡∏ß‡∏±‡∏í‡∏ô‡∏ò‡∏£‡∏£‡∏°‡πÑ‡∏ó‡∏•‡∏∑‡πâ‡∏≠‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à‡∏ô‡∏∞‡∏Ñ‡∏∞ üéâ"
- "‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û" ‚Üí "‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ï‡πâ‡∏≠‡∏ô‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏∞! ‡∏´‡∏ô‡∏µ‡∏°‡∏≤‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏≤‡∏û‡∏±‡∏Å‡∏ú‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏ô‡∏ô‡∏¥‡∏î‡∏ô‡∏∂‡∏á‡∏ô‡∏∞‡∏Ñ‡∏∞ üòä"
"""
    
    return await get_groq_response(
        [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_query}
        ],
        model_name=settings.GROQ_SMALL_TALK_MODEL,
        temperature=0.7 
    )
