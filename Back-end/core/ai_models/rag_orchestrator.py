import asyncio
import logging
import os
import random
import re
import math
import urllib.parse
import json
import time
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict, List, Optional
from bson import ObjectId

from sentence_transformers import CrossEncoder

# üÜï ‡πÅ‡∏¢‡∏Å Gemini ‡πÅ‡∏•‡∏∞ Groq handlers ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏Å‡∏±‡∏ô
from core.ai_models.gemini_handler import get_gemini_response
from core.ai_models.groq_handler import get_groq_response, get_small_talk_response
from core.ai_models.query_interpreter import QueryInterpreter
from core.ai_models.youtube_handler import youtube_handler_instance
from core.config import settings
from .handlers.analytics_handler import AnalyticsHandler
from core.database.mongodb_manager import MongoDBManager
from core.database.qdrant_manager import QdrantManager
from core.tools.image_search_tool import image_search_tool_instance
from core.services.calculator_service import calculator_service  # üßÆ ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ñ‡∏¥‡∏î‡πÄ‡∏•‡∏Ç Python
from utils.helper_functions import create_synthetic_document
from .services.session_manager import SessionManager
from .services.navigation_service import NavigationService
from .services.prompt_engine import PromptEngine
from core.services.image_service import ImageService
from core.services.knowledge_gap_service import KnowledgeGapService

BACKEND_ROOT = Path(__file__).resolve().parent.parent.parent

def construct_full_image_url(image_path: str | None) -> str | None:
    if not image_path: return None
    if image_path.startswith(('http://', 'https://')):
        return image_path
    if image_path.startswith('/'):
        return f"http://{settings.API_HOST}:{settings.API_PORT}{image_path}"
    return image_path

class RAGOrchestrator:
    def __init__(
        self,
        mongo_manager: MongoDBManager,
        qdrant_manager: QdrantManager,
        query_interpreter: QueryInterpreter,
    ):
        logging.info("‚öôÔ∏è  ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö RAG Orchestrator (Refactored V8.1)...")
        self.mongo_manager = mongo_manager
        self.qdrant_manager = qdrant_manager
        self.query_interpreter = query_interpreter
        self.session_manager = SessionManager(mongo_manager)
        self.prompt_engine = PromptEngine()
        self.nav_service = NavigationService(mongo_manager, self.prompt_engine)
        self.image_service = ImageService(mongo_manager)

        self.reranker_model_name = settings.RERANKER_MODEL_NAME
        self.device = settings.DEVICE

        logging.info(f"üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• Re-ranker ('{self.reranker_model_name}' ‡∏ö‡∏ô '{self.device}')...")
        # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• CrossEncoder ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏≥ Reranking
        # ‡∏ä‡πà‡∏ß‡∏¢‡∏à‡∏±‡∏î‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ç‡∏≠‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏à‡∏≠ ‡πÉ‡∏´‡πâ‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Ç‡∏∂‡πâ‡∏ô
        self.reranker = CrossEncoder(self.reranker_model_name, device=self.device)
        logging.info("‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• Re-ranker ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")

        self.log_collection = self.mongo_manager.get_collection("query_logs")
        
        self.analytics_handler = AnalyticsHandler(
            mongo_manager=self.mongo_manager,
            query_interpreter=self.query_interpreter,
            orchestrator_callback=self.answer_query
        )
        
        # üß† [Self-Correcting RAG] Knowledge Gap Service
        self.knowledge_gap_service = KnowledgeGapService(mongo_manager, qdrant_manager)
        
        logging.info("‚úÖ RAG Orchestrator ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")

    def _prepare_source_and_image_data(self, docs_to_show: List[Dict[str, Any]]) -> Dict[str, Any]:
        source_info: List[dict] = []
        static_image_gallery: List[str] = []
        processed_prefixes = set()
        for doc in docs_to_show:
            if not doc: continue
            
            # Safe access: Handle if metadata is None or missing
            metadata = doc.get("metadata") or {}
            prefix = metadata.get("image_prefix")
            
            doc_images = []
            if prefix and prefix not in processed_prefixes:
                found_images = self.image_service.find_all_images_by_prefix(prefix)
                if found_images:
                    doc_images.extend(found_images)
                    for img_url in found_images:
                        if img_url not in static_image_gallery:
                            static_image_gallery.append(img_url)
                    processed_prefixes.add(prefix)
            
            source_info.append({
                "title": doc.get("title", "N/A"),
                "summary": doc.get("summary", ""),
                "image_urls": doc_images[: settings.SOURCE_CARD_IMAGE_LIMIT],
            })
        return {"source_info": source_info, "image_gallery": static_image_gallery}

    async def _handle_welcome_flow(self, session_id: Optional[str] = None, **kwargs) -> dict:
        # üÜï Dynamic Greeting (Requested by User)
        # ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ Fixed Text ‡πÅ‡∏•‡πâ‡∏ß ‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• 8B (Small Talk) ‡∏Ñ‡∏¥‡∏î‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÄ‡∏≠‡∏á‡πÄ‡∏•‡∏¢
        corrected_query = kwargs.get('corrected_query') or "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ"
        
        logging.info(f"üëã [Welcome] Generating Dynamic Greeting for: '{corrected_query}'")
        final_answer = await get_small_talk_response(user_query=corrected_query)
        
        return {
            "answer": final_answer,
            "action": None, # ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á Force Analytics ‡πÅ‡∏•‡πâ‡∏ß
            "action_payload": None, "image_url": None, "image_gallery": [], "sources": [],
        }

    def _map_frontend_intent(self, frontend_intent: str) -> str:
        """
        üÜï ‡πÅ‡∏õ‡∏•‡∏á frontend intent ‡πÄ‡∏õ‡πá‡∏ô internal intent
        ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ LLM ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå - ‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î tokens!
        """
        intent_map = {
            "MUSIC": "PLAY_MUSIC",
            "NAVIGATION": "NAVIGATE_TO",
            "FAQ": "INFORMATIONAL",
            "GENERAL": "INFORMATIONAL",
            "WELCOME": "WELCOME_FLOW",
            # ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ñ‡∏¥‡∏î‡πÄ‡∏•‡∏Ç‡∏ñ‡∏π‡∏Å‡∏•‡∏ö‡∏≠‡∏≠‡∏Å - ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÇ‡∏î‡∏¢ widget ‡∏ù‡∏±‡πà‡∏á frontend
        }
        return intent_map.get(frontend_intent.upper(), "INFORMATIONAL")

    async def _handle_small_talk(self, corrected_query: str, **kwargs) -> dict:
        # üÜï Check if Frontline (via Interpreter) already provided a reply
        interpretation = kwargs.get("interpretation", {})
        direct_reply = interpretation.get("reply")
        
        if direct_reply:
            logging.info("‚ö° [SmallTalk] Using Direct Reply from Frontline/Assistant")
            final_answer = direct_reply
        else:
            # Fallback to Llama 8B if Frontline didn't give a reply (Legacy)
            final_answer = await get_small_talk_response(user_query=corrected_query)
            
        return {"answer": final_answer, "action": None, "sources": [], "image_url": None, "image_gallery": []}

    async def _handle_calculate(self, corrected_query: str, **kwargs) -> dict:
        """
        üßÆ Calculator handler - Hybrid Mode:
        Pure math ‚Üí Python ‡∏ï‡∏£‡∏á | Text+math ‚Üí AI 70B ‡∏ä‡πà‡∏ß‡∏¢‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
        """
        return await calculator_service.calculate(corrected_query)

    async def _handle_play_music(self, corrected_query: str = "", **kwargs) -> dict:
        """
        üéµ Play music handler - ‡πÉ‡∏ä‡πâ corrected_query ‡πÄ‡∏õ‡πá‡∏ô search term ‡∏ï‡∏£‡∏á‡πÜ
        Frontend ‡∏™‡πà‡∏á song name ‡∏°‡∏≤‡πÉ‡∏ô query ‡πÅ‡∏•‡πâ‡∏ß
        """
        search_query = corrected_query.strip() if corrected_query else ""
        
        # ‡∏ñ‡πâ‡∏≤ query ‡∏ß‡πà‡∏≤‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡∏¥‡∏î‡πÄ‡∏û‡∏•‡∏á‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ (‡πÄ‡∏û‡∏•‡∏á‡∏Ñ‡∏≥‡πÄ‡∏°‡∏∑‡∏≠‡∏á/‡∏ô‡πà‡∏≤‡∏ô)
        generic_triggers = ["‡πÄ‡∏û‡∏•‡∏á", "‡πÄ‡∏õ‡∏¥‡∏î‡πÄ‡∏û‡∏•‡∏á", "‡∏ü‡∏±‡∏á‡πÄ‡∏û‡∏•‡∏á", "music", "song", "‡∏≠‡∏¢‡∏≤‡∏Å‡∏ü‡∏±‡∏á‡πÄ‡∏û‡∏•‡∏á", ""]
        if search_query.lower() in generic_triggers:
            logging.info("üéµ [Music] Generic request detected -> Defaulting to '‡πÄ‡∏û‡∏•‡∏á‡∏Ñ‡∏≥‡πÄ‡∏°‡∏∑‡∏≠‡∏á ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÜ'")
            search_query = "‡πÄ‡∏û‡∏•‡∏á‡∏Ñ‡∏≥‡πÄ‡∏°‡∏∑‡∏≠‡∏á ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÜ"

        # (Logic continues to search_music below...)
        
        logging.info(f"üéµ [Music] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏û‡∏•‡∏á‡πÉ‡∏ô YouTube ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö: '{search_query}'")
        search_results = await youtube_handler_instance.search_music(query=search_query)
        
        if not search_results:
            return {
                "answer": f"‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞ ‡∏´‡∏≤‡πÄ‡∏û‡∏•‡∏á '{search_query}' ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡πÄ‡∏•‡∏¢‡∏Ñ‡πà‡∏∞ ‡∏•‡∏≠‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∑‡πà‡∏ô‡∏î‡∏π‡∏°‡∏±‡πâ‡∏¢‡∏Ñ‡∏∞?",
                "action": None,
                "action_payload": None,
                "sources": [], "image_url": None, "image_gallery": []
            }
        
        return {
            "answer": f"‡∏à‡∏±‡∏î‡πÉ‡∏´‡πâ‡∏ï‡∏≤‡∏°‡∏Ñ‡∏≥‡∏Ç‡∏≠‡∏Ñ‡πà‡∏∞! ‡πÄ‡∏û‡∏•‡∏á‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö **'{search_query}'**",
            "action": "SHOW_SONG_CHOICES", 
            "action_payload": search_results,
            "sources": [], "image_url": None, "image_gallery": []
        }

    # _handle_system_command ‡∏ñ‡∏π‡∏Å‡∏•‡∏ö‡∏≠‡∏≠‡∏Å - ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ñ‡∏¥‡∏î‡πÄ‡∏•‡∏Ç‡∏ñ‡∏π‡∏Å‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÇ‡∏î‡∏¢ frontend widget ‡πÅ‡∏•‡πâ‡∏ß

    async def _handle_informational(
        self, corrected_query: str, entity: Optional[str], sub_queries: List[str], mode: str, 
        turn_count: int = 1, session_id: Optional[str] = None, ai_mode: str = "fast", 
        original_query: str = None,
        interpretation: Dict[str, Any] = None,
        language: str = None, # üÜï Accept language arg
        **kwargs
    ) -> dict:
        interpretation = interpretation or kwargs.get("interpretation", {})
        
        unique_queries = interpretation.get("sub_queries") or [corrected_query]
        entity = interpretation.get("entity")
        
        # üÜï [Broad Query Detection] ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Å‡∏ß‡πâ‡∏≤‡∏á‡πÜ
        broad_query_keywords = ["‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥", "‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß", "‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà", "‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à", "‡∏ó‡∏µ‡πà‡πÑ‡∏´‡∏ô‡∏î‡∏µ", "‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á", "‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£", "recommend"]
        is_broad_query = any(kw in corrected_query for kw in broad_query_keywords) and not entity
        
        if is_broad_query:
            logging.info(f"üîç [Broad Query] Detected! Expanding queries for better coverage...")
            # Expand query ‡πÉ‡∏´‡πâ specific ‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô
            unique_queries = [
                corrected_query,
                "‡∏ß‡∏±‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç ‡∏ô‡πà‡∏≤‡∏ô ‡∏¢‡∏≠‡∏î‡∏ô‡∏¥‡∏¢‡∏°",
                "‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß ‡∏ô‡πà‡∏≤‡∏ô ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥",
                "‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥ ‡∏î‡∏≠‡∏¢ ‡∏ô‡πà‡∏≤‡∏ô",
            ]
            logging.info(f"üîç [Broad Query] Expanded to: {unique_queries}")
        
        print(f"DEBUG PRINT: _handle_informational CALLED. Entity=[{entity}]")
        logging.info(f"üîé [DEBUG] _handle_informational Called. Args Entity: {entity}, Kwargs Interpretation Keys: {interpretation.keys()}")
        if entity:
            logging.info(f"üîé [DEBUG] Entity is present: '{entity}'")
        else:
            logging.info(f"üîé [DEBUG] Entity is NONE or EMPTY.")
        
        
        # üõ°Ô∏è Construct Metadata Filter (Location + Category)
        # üÜï [District Detection] ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏≥‡πÄ‡∏†‡∏≠‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
        NAN_DISTRICTS = [
            "‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡∏ô‡πà‡∏≤‡∏ô", "‡πÄ‡∏°‡∏∑‡∏≠‡∏á", "‡πÅ‡∏°‡πà‡∏à‡∏£‡∏¥‡∏°", "‡∏ö‡πâ‡∏≤‡∏ô‡∏´‡∏•‡∏ß‡∏á", "‡∏ô‡∏≤‡∏ô‡πâ‡∏≠‡∏¢", "‡∏õ‡∏±‡∏ß", "‡∏ó‡πà‡∏≤‡∏ß‡∏±‡∏á‡∏ú‡∏≤", 
            "‡πÄ‡∏ß‡∏µ‡∏¢‡∏á‡∏™‡∏≤", "‡∏ó‡∏∏‡πà‡∏á‡∏ä‡πâ‡∏≤‡∏á", "‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡∏Å‡∏•‡∏≤‡∏á", "‡∏ô‡∏≤‡∏´‡∏°‡∏∑‡πà‡∏ô", "‡∏™‡∏±‡∏ô‡∏ï‡∏¥‡∏™‡∏∏‡∏Ç", "‡∏ö‡πà‡∏≠‡πÄ‡∏Å‡∏•‡∏∑‡∏≠", 
            "‡∏™‡∏≠‡∏á‡πÅ‡∏Ñ‡∏ß", "‡∏†‡∏π‡πÄ‡∏û‡∏µ‡∏¢‡∏á"
        ]
        
        # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏≥‡πÄ‡∏†‡∏≠‡πÉ‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
        detected_district = None
        for district in NAN_DISTRICTS:
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á "‡∏≠‡∏≥‡πÄ‡∏†‡∏≠‡∏õ‡∏±‡∏ß" ‡πÅ‡∏•‡∏∞ "‡∏õ‡∏±‡∏ß" ‡∏´‡∏£‡∏∑‡∏≠ "‡∏ó‡∏µ‡πà‡∏õ‡∏±‡∏ß"
            if f"‡∏≠‡∏≥‡πÄ‡∏†‡∏≠{district}" in corrected_query or f"‡∏≠.{district}" in corrected_query:
                detected_district = district
                break
            elif district in corrected_query and len(district) > 2:  # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô match ‡∏Ñ‡∏≥‡∏™‡∏±‡πâ‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
                detected_district = district
                break
        
        location_filter = {}
        if detected_district:
            location_filter["district"] = detected_district
            logging.info(f"üìç [District Filter] ‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏≠‡∏≥‡πÄ‡∏†‡∏≠: '{detected_district}' - ‡∏à‡∏∞‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÉ‡∏ô‡∏≠‡∏≥‡πÄ‡∏†‡∏≠‡∏ô‡∏µ‡πâ")
        
        category = interpretation.get("category")
        
        metadata_filter = location_filter.copy()
        if category:
            metadata_filter["category"] = category
            logging.info(f"üè∑Ô∏è [Filter] Applying Category Filter: {category}")
        
        # üÜï [SMART] Always exclude district/province data from search results
        # ‡πÑ‡∏°‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≥‡πÄ‡∏†‡∏≠" ‡∏´‡∏£‡∏∑‡∏≠ "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î" ‡πÉ‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        EXCLUDED_CATEGORIES = [
            "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≥‡πÄ‡∏†‡∏≠",
            "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î",
            "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏®‡∏£‡∏©‡∏ê‡∏Å‡∏¥‡∏à"
        ]
        metadata_filter["exclude_categories"] = EXCLUDED_CATEGORIES
        logging.info(f"üö´ [Filter] Excluding categories: {EXCLUDED_CATEGORIES}")

        # 2. ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Retrieval)
        # ‡πÉ‡∏ä‡πâ Qdrant ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢ (Semantic Search)
        # ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏ó‡∏∏‡∏Å sub-query ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°
        mongo_ids_from_search = []
        qdrant_results_combined = []
        
        logging.info(f"üîé [RAG] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•... (Queries: {unique_queries}, Filter: {metadata_filter})")

        # 1.5 SMART FEATURE: Direct Entity Search
        # If Interpreter detected an entity, try to find it directly in DB (Accuracy Boost)
        # This bypasses Semantic Search limitations for specific names.
        found_direct_entity = False
        if entity:
             logging.info(f"üéØ [RAG] Specific Entity Detected: '{entity}' - Attempting Direct DB Lookup...")
             direct_doc = await asyncio.to_thread(self.mongo_manager.get_location_by_title, entity)
             
             if direct_doc:
                 logging.info(f"‚úÖ [RAG] Found Direct Match: {direct_doc.get('title')}")
                 found_direct_entity = True
                 mock_result = {
                    "payload": {
                        "mongo_id": str(direct_doc.get("_id")),
                        "title": direct_doc.get("title"),
                        "summary": direct_doc.get("summary"),
                        "category": direct_doc.get("category"),
                        "slug": direct_doc.get("slug"),
                        "location_data": direct_doc.get("location_data"),
                        "image_urls": direct_doc.get("image_urls", []),
                        "metadata": direct_doc.get("metadata", {}),
                        "is_direct_match": True # Mark as direct match
                    },
                    "score": 1.5 # Boost score above everything else (Typical vector score < 1.0)
                 }
                 qdrant_results_combined.append(mock_result)
                 # üÜï FIX: Add ID to processing list immediately!
                 mongo_ids_from_search.append(str(direct_doc.get("_id"))) 

        # üî• SMART FEATURE: Trending Recommendations for Broad Queries
        # If no specific entity is requested AND no specific filters (except maybe general category),
        # we consider it a "Broad Query" and inject recommended tourist attractions.
        is_broad_query = (not found_direct_entity) and (entity is None) and (not location_filter)
        
        if is_broad_query:
            logging.info("üî• [RAG] Broad Query Detected! Fetching Recommended Attractions...")
            try:
                # üÜï ‡πÉ‡∏ä‡πâ get_recommended_attractions ‡πÅ‡∏ó‡∏ô get_trending_locations
                # ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏≠‡∏≥‡πÄ‡∏†‡∏≠
                recommended_docs = await asyncio.to_thread(
                    self.mongo_manager.get_recommended_attractions, 
                    limit=5
                )
                
                if recommended_docs:
                    logging.info(f"üéØ [Recommended] Found {len(recommended_docs)} attractions")
                    for doc in recommended_docs:
                        logging.info(f"   - {doc.get('title')} ({doc.get('category')})")
                        # Create mock result similar to above
                        mock_res = {
                            "payload": {
                                "mongo_id": str(doc.get("_id")),
                                **doc, # Include other fields
                                "is_recommended": True # Flag for boost
                            },
                            "score": 0.8 # Decent baseline score
                        }
                        qdrant_results_combined.append(mock_res)
                else:
                    logging.warning("‚ö†Ô∏è [Recommended] No attractions found, falling back to semantic search")
            except Exception as e:
                logging.error(f"‚ùå [RAG] Error fetching recommended attractions: {e}")

        if not found_direct_entity:
            for q in unique_queries:
                # Pass metadata_filter to search_similar
                qdrant_results = await self.qdrant_manager.search_similar(
                    query_text=q, 
                    top_k=settings.QDRANT_TOP_K,
                    metadata_filter=metadata_filter # üÜï Apply Merged Filter
                )
                qdrant_results_combined.extend(qdrant_results)
                for res in qdrant_results:
                    if res.payload and res.payload.get("mongo_id"):
                        mongo_ids_from_search.append(res.payload.get("mongo_id"))

        # [‡πÅ‡∏ú‡∏ô‡∏™‡∏≥‡∏£‡∏≠‡∏á] ‡∏´‡∏≤‡∏Å Qdrant ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏∞‡∏ö‡∏ö‡∏•‡πà‡∏°) ‡πÉ‡∏´‡πâ‡∏•‡∏≠‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏ô MongoDB ‡πÅ‡∏ó‡∏ô
        if not qdrant_results_combined:
            logging.info("‚ö†Ô∏è [RAG] Qdrant ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏•‡∏≠‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏ô MongoDB ‡πÅ‡∏ó‡∏ô...")
            # ‡πÉ‡∏ä‡πâ entity ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ ‡∏°‡∏¥‡∏â‡∏∞‡∏ô‡∏±‡πâ‡∏ô‡πÉ‡∏ä‡πâ corrected_query
            search_term = entity if entity else corrected_query
            
            # TODO: Improve MongoDB Fallback to support filter (Optional for now)
            logging.info(f"‚ö†Ô∏è [RAG] Qdrant ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏•‡∏≠‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏ô MongoDB ‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤: '{search_term}'")
            mongo_results = await asyncio.to_thread(self.mongo_manager.get_location_by_title, search_term)
            if mongo_results:
                # ‡πÅ‡∏õ‡∏•‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å MongoDB ‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ö payload ‡∏Ç‡∏≠‡∏á Qdrant
                # ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ç‡∏≠‡∏á Qdrant ‡∏°‡∏±‡∏Å‡∏à‡∏∞‡∏°‡∏µ 'payload' ‡πÅ‡∏•‡∏∞ 'score'
                # ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡∏•‡∏≠‡∏á‡πÅ‡∏ö‡∏ö Qdrant ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏°‡πà‡∏≥‡πÄ‡∏™‡∏°‡∏≠
                mock_qdrant_result = {
                    "payload": {
                        "mongo_id": str(mongo_results.get("_id")), # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÑ‡∏î‡πâ‡∏£‡∏ß‡∏° _id ‡πÑ‡∏ß‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏†‡∏≤‡∏¢‡∏´‡∏•‡∏±‡∏á
                        "title": mongo_results.get("title"),
                        "summary": mongo_results.get("summary"),
                        "category": mongo_results.get("category"),
                        "slug": mongo_results.get("slug"),
                        "location_data": mongo_results.get("location_data"),
                        "image_urls": mongo_results.get("image_urls", []),
                        "metadata": mongo_results.get("metadata", {})
                    },
                    "score": 1.0 # ‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏™‡∏≥‡∏£‡∏≠‡∏á
                }
                qdrant_results_combined.append(mock_qdrant_result)
                mongo_ids_from_search.append(str(mongo_results.get("_id")))
                logging.info(f"‚úÖ [RAG] ‡∏û‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏™‡∏≥‡∏£‡∏≠‡∏á‡πÉ‡∏ô MongoDB: {mongo_results.get('title')}")


        unique_ids = list(dict.fromkeys(mongo_ids_from_search))
        
        # Capture Trending IDs to re-apply metadata later
        # FIX: Check if res is object (ScoredPoint) or dict
        def get_payload(res):
            if hasattr(res, 'payload'): return res.payload
            if isinstance(res, dict): return res.get('payload', {})
            return {}

        trending_ids = {get_payload(res).get('mongo_id') for res in qdrant_results_combined 
                        if get_payload(res).get('is_trending')}
                        
        direct_match_ids = {get_payload(res).get('mongo_id') for res in qdrant_results_combined 
                            if get_payload(res).get('is_direct_match')}

        recommended_ids = {get_payload(res).get('mongo_id') for res in qdrant_results_combined 
                            if get_payload(res).get('is_recommended')}

        docs_with_synthetic = []
        
        # Optimize: Fetch all docs at once by ID
        found_mongo_docs = []
        if unique_ids:
             found_mongo_docs = await asyncio.to_thread(
                 lambda: list(self.mongo_manager.get_collection("nan_locations").find({"_id": {"$in": [ObjectId(uid) for uid in unique_ids if ObjectId.is_valid(uid)]}}))
             )
        
        # Map ID -> Doc
        doc_map = {str(d["_id"]): d for d in found_mongo_docs}
        
        for doc_id in unique_ids:
            doc = doc_map.get(doc_id)
            if doc:
                 # Re-inject trending/direct flags
                 if doc_id in trending_ids: doc['is_trending'] = True
                 if doc_id in direct_match_ids: doc['is_direct_match'] = True
                 if doc_id in recommended_ids: doc['is_recommended'] = True
                 
                 synthetic_doc = create_synthetic_document(doc)
                 docs_with_synthetic.append((doc, synthetic_doc))
        
        if not docs_with_synthetic:
             return {
                "answer": f"‡∏ô‡πâ‡∏≠‡∏á‡∏ô‡πà‡∏≤‡∏ô‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö **'{corrected_query}'** ‡πÅ‡∏•‡πâ‡∏ß‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡πÄ‡∏•‡∏¢‡∏Ñ‡πà‡∏∞ üòÖ ‡∏•‡∏≠‡∏á‡∏ñ‡∏≤‡∏°‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏≠‡∏∑‡πà‡∏ô ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏≠‡∏∑‡πà‡∏ô‡∏î‡∏π‡∏°‡∏±‡πâ‡∏¢‡∏Ñ‡∏∞?",
                "action": None,
                "sources": [], "image_url": None, "image_gallery": []
            }
        
        # 3. Reranking (Cross-Encoder)
        # ‡∏ô‡∏≥‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏´‡∏≤‡πÄ‡∏à‡∏≠ ‡∏°‡∏≤‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô (User Query) ‡∏≠‡∏µ‡∏Å‡∏£‡∏≠‡∏ö ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠
        sentence_pairs = [[corrected_query, synthetic_doc] for doc, synthetic_doc in docs_with_synthetic]
        
        # ‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô (Score) ‡∏¢‡∏¥‡πà‡∏á‡πÄ‡∏¢‡∏≠‡∏∞‡∏¢‡∏¥‡πà‡∏á‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏°‡∏≤‡∏Å
        scores = await asyncio.to_thread(self.reranker.predict, sentence_pairs, show_progress_bar=False)
        
        # üÜï [Score Boosting V2] ‡∏î‡∏±‡∏ô‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô Trending/Direct/Recommended ‡πÉ‡∏´‡πâ‡∏ä‡∏ô‡∏∞ Semantic
        final_scores = []
        for score, (doc, _) in zip(scores, docs_with_synthetic):
            boosted_score = float(score)
            if doc.get('is_direct_match'):
                boosted_score = max(boosted_score, 0.95)  # Direct Match = Near perfect
            elif doc.get('is_recommended') and is_broad_query:
                # üÜï Recommended items ‡πÑ‡∏î‡πâ boost ‡∏™‡∏π‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Å‡∏ß‡πâ‡∏≤‡∏á
                boosted_score = max(boosted_score, 0.80)
                logging.info(f"üåü [Boost] Recommended item '{doc.get('title')}' boosted to {boosted_score:.2f}")
            elif doc.get('is_trending'):
                boosted_score = max(boosted_score, 0.75)
            final_scores.append(boosted_score)
        
        # üîç [Debug Log] ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô Reranking ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£
        logging.info(f"üìä [Reranking] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏à‡∏±‡∏î‡∏•‡∏≥‡∏î‡∏±‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ {len(final_scores)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£...")
        for i, (score, (doc, _)) in enumerate(zip(final_scores, docs_with_synthetic)):
            logging.info(f"   üîπ ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£: {doc.get('title')} | ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô: {score:.4f} | Recommended: {doc.get('is_recommended', False)} | Trending: {doc.get('is_trending', False)}")

        # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡πÉ‡∏´‡∏°‡πà‡∏ï‡∏≤‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô Boosted (‡∏°‡∏≤‡∏Å‡πÑ‡∏õ‡∏ô‡πâ‡∏≠‡∏¢)
        reranked_results = sorted(zip(final_scores, docs_with_synthetic), key=lambda x: x[0], reverse=True)
        
        # üîç [Debug Log] ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏´‡∏•‡∏±‡∏á‡∏à‡∏±‡∏î‡∏•‡∏≥‡∏î‡∏±‡∏ö (Top 3)
        logging.info(f"üèÜ [Reranking] 3 ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡πÅ‡∏£‡∏Å‡∏´‡∏•‡∏±‡∏á‡∏à‡∏±‡∏î‡∏•‡∏≥‡∏î‡∏±‡∏ö‡πÉ‡∏´‡∏°‡πà:")
        for i, (score, (doc, _)) in enumerate(reranked_results[:3]):
             logging.info(f"   ü•á #{i+1}: {doc.get('title')} (‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô: {score:.4f})")

        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î Top K ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡πÅ‡∏£‡∏Å
        top_k = settings.TOP_K_RERANK_VOICE if mode == "voice" else settings.TOP_K_RERANK_TEXT
        
        # üõ°Ô∏è [Self-Correction] Confidence Check - Updated for Broad Queries
        is_low_confidence = False
        if reranked_results:
            top_score = reranked_results[0][0]
            # üÜï Trust Recommended items for broad queries too
            has_trusted_source = any(
                d.get('is_trending') or d.get('is_direct_match') or d.get('is_recommended') 
                for _, (d, _) in reranked_results[:top_k]
            )
            
            # üÜï Broad queries with trusted sources should not be flagged as low confidence
            if is_broad_query and has_trusted_source:
                logging.info(f"‚úÖ [Confidence] Broad query with trusted sources - NOT flagging low confidence")
                is_low_confidence = False
            elif top_score < settings.RAG_CONFIDENCE_THRESHOLD and not has_trusted_source:
                is_low_confidence = True
                logging.warning(f"‚ö†Ô∏è [Low Confidence] ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î ({top_score:.4f}) ‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏Å‡∏ì‡∏ë‡πå ({settings.RAG_CONFIDENCE_THRESHOLD})")
                # üß† [Self-Correcting RAG] ‡∏à‡∏∞ Log ‡∏´‡∏•‡∏±‡∏á‡πÑ‡∏î‡πâ AI Response
        
        final_docs = [doc for score, (doc, _) in reranked_results[:top_k]]
        
        context_str = ""
        if final_docs:
            context_parts = []
            for i, doc in enumerate(final_docs, 1):
                doc_text = create_synthetic_document(doc)
                if doc.get('is_trending'):
                    doc_text = f"üî• [POPULAR/TRENDING] ‡∏ô‡∏µ‡πà‡∏¢‡∏≠‡∏î‡∏ô‡∏¥‡∏¢‡∏°‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏ô‡∏µ‡πâ: {doc_text}"
                context_parts.append(f"[Document {i}]\nTitle: {doc.get('title')}\nInfo: {doc_text}")
            context_str = "\n\n----------------\n\n".join(context_parts)

        history = []
        if session_id:
            session = await self.session_manager.get_session(session_id)
            history = session.get("history", [])

        prompt_dict = self.prompt_engine.build_rag_prompt(
            user_query=original_query or corrected_query, 
            context=context_str, 
            history=history,
            ai_mode=ai_mode,
            is_low_confidence=is_low_confidence, 
            language_hint=language # üÜï Pass language hint
        )
        
        messages = [
            {"role": "system", "content": prompt_dict["system"]},
            {"role": "user", "content": prompt_dict["user"]}
        ]

        logging.info(f"ü§ñ [LLM] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÉ‡∏ä‡πâ‡πÇ‡∏´‡∏°‡∏î AI: {ai_mode}")
        
        if ai_mode == "detailed":
            # ‡πÉ‡∏ä‡πâ Gemini ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î 
            raw_answer = await get_gemini_response(
                user_query=prompt_dict["user"],
                system_prompt=prompt_dict["system"],
                max_tokens=8192
            )
        else:
            # ‡πÉ‡∏ä‡πâ Groq/Llama ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß
            try:
                raw_answer = await get_groq_response(
                    messages=messages,
                    model_name=settings.GROQ_LLAMA_MODEL
                )
            except Exception as e:
                logging.error(f"‚ö†Ô∏è [Groq] ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {e} ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÑ‡∏õ‡πÉ‡∏ä‡πâ Gemini...")
                # ‡∏™‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡πÉ‡∏ä‡πâ Gemini ‡πÇ‡∏î‡∏¢‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
                raw_answer = await get_gemini_response(
                    user_query=prompt_dict["user"],
                    system_prompt=prompt_dict["system"],
                    max_tokens=8192
                )
        
        # üß† [Self-Correcting RAG] Log low confidence queries WITH AI response
        if is_low_confidence:
            await self.knowledge_gap_service.log_unanswered(
                query=corrected_query,
                score=top_score,
                session_id=session_id,
                ai_response=raw_answer,
                context=context_str
            )
        
        final_answer_with_images = await self.image_service.inject_images_into_text(raw_answer)
        
        docs_to_show = final_docs[:5]
        prepared_data = self._prepare_source_and_image_data(docs_to_show)
        static_gallery = prepared_data["image_gallery"]
        
        if len(static_gallery) < settings.IMAGE_FALLBACK_THRESHOLD and final_docs:
            # üéØ [Image Search Improvement] ‡πÉ‡∏ä‡πâ Entity ‡∏à‡∏≤‡∏Å LLM ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≠‡∏¢‡πÉ‡∏ä‡πâ Title ‡∏à‡∏≤‡∏Å Doc
            target_topic = entity if entity else final_docs[0].get('title')
            search_q = f"{target_topic} ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ô‡πà‡∏≤‡∏ô"
            logging.info(f"üñºÔ∏è [Image Fallback] Searching Google Images for: '{search_q}'") 
            try:
                google_imgs = await image_search_tool_instance.get_image_urls(search_q, max_results=settings.GOOGLE_IMAGE_MAX_RESULTS)
                for url in google_imgs:
                    if url not in static_gallery: static_gallery.append(url)
            except Exception as e:
                logging.error(f"‚ùå ‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û Google ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {e}")

        return {
            "answer": final_answer_with_images,
            "action": None,
            "image_url": None, 
            "image_gallery": static_gallery[:settings.FINAL_GALLERY_IMAGE_LIMIT],
            "sources": prepared_data["source_info"],
            "show_slide": True, # ‚úÖ Explicitly show slide for informational content
            "_primary_topic": final_docs[0].get("title") if final_docs else None # ‡∏™‡πà‡∏á Topic ‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å State
        }

    async def get_navigation_list(self, user_lat: float = None, user_lon: float = None) -> List[Dict[str, Any]]:
        try:
            collection = self.mongo_manager.get_collection("nan_locations")
            if collection is None:
                logging.warning("‚ö†Ô∏è [NavList] ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ MongoDB ‡πÑ‡∏î‡πâ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡πà‡∏á‡∏Ñ‡∏∑‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡∏•‡∏≠‡∏á")
                return []

            docs = await asyncio.to_thread(lambda: list(collection.find(
                {"doc_type": "Location"}, 
                {"title":1, "slug":1, "topic":1, "summary":1, "category":1, "location_data":1, "metadata":1, "_id":0}
            )))
            
            if user_lat and user_lon:
                docs = self.nav_service.sort_locations_by_distance(docs, user_lat, user_lon)
            
            for doc in docs:
                imgs = self.image_service.get_location_images(doc)
                doc["image_urls"] = [imgs[0]] if imgs else []
            
            return docs
        except Exception as e:
            logging.error(f"‚ùå [NavList] ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
            return []

    async def handle_get_directions(self, entity_slug: str, user_lat: float = None, user_lon: float = None, skip_cleaning: bool = False) -> dict:
        return await self.nav_service.handle_get_directions(
            entity_slug=entity_slug, 
            user_lat=user_lat, 
            user_lon=user_lon,
            skip_cleaning=skip_cleaning
        )
    
    async def answer_query(self, query: str, mode: str = "text", session_id: Optional[str] = None, ai_mode: str = "fast", frontend_intent: str = None, language: str = None, slug: Optional[str] = None, entity_query: Optional[str] = None, **kwargs) -> dict:
        """
        ai_mode: 'fast' = Llama/Groq, 'detailed' = Gemini
        frontend_intent: 'GENERAL' | 'MUSIC' | 'NAVIGATION' | 'FAQ' (‡∏à‡∏≤‡∏Å Frontend)
        language: 'th' | 'en' (Hint from frontend)
        """
        session_data = await self.session_manager.get_session(session_id)
        current_turn = session_data.get("turn_count", 0) + 1
        history = session_data.get("history", []) 
        
        if session_id and session_data.get("awaiting") == "analytics_origin_or_topic":
            self.session_manager.collection.update_one({"session_id": session_id}, {"$unset": {"awaiting": ""}})
            return await self.analytics_handler.handle_analytics_response(query, session_id, mode)

        start_time = time.perf_counter() # ‚è±Ô∏è Start Timer

        logging.info(f"üîÑ [Session] ID: {session_id} | ‡∏£‡∏≠‡∏ö‡∏ó‡∏µ‡πà: {current_turn} | ‡πÇ‡∏´‡∏°‡∏î AI: {ai_mode} | ‡πÄ‡∏à‡∏ï‡∏ô‡∏≤‡∏à‡∏≤‡∏Å Frontend: {frontend_intent}")

        # üÜï ‡πÉ‡∏ä‡πâ frontend_intent ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á - ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏Å LLM ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏à‡∏ï‡∏ô‡∏≤
        # Note: "LINE" frontend_intent should use LLM analysis to detect music/navigation intents
        if frontend_intent and frontend_intent not in ["GENERAL", "LINE", None]:
            # Frontend ‡∏ö‡∏≠‡∏Å intent ‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß ‡πÉ‡∏ä‡πâ‡πÄ‡∏•‡∏¢!
            intent = self._map_frontend_intent(frontend_intent)
            corrected_query = query
            entity = None  # ‡∏à‡∏∞‡∏´‡∏≤‡∏à‡∏≤‡∏Å query ‡∏´‡∏£‡∏∑‡∏≠ Qdrant search
            
            # üöÄ [Direct Bypass] ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ intent NAVIGATE_TO + slug/entity_query ‡πÉ‡∏´‡πâ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÄ‡∏•‡∏¢!
            if intent == "NAVIGATE_TO":
                 target_entity = slug or entity_query or query
                 if target_entity:
                     logging.info(f"üèéÔ∏è [Quick Nav] ‡∏Ç‡πâ‡∏≤‡∏° Logic ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏≥‡∏ó‡∏≤‡∏á‡πÑ‡∏õ‡∏¢‡∏±‡∏á: '{target_entity}'")
                     return await self.handle_get_directions(entity_slug=target_entity)

            logging.info(f"üöÄ [Intent] ‡πÉ‡∏ä‡πâ‡πÄ‡∏à‡∏ï‡∏ô‡∏≤‡∏à‡∏≤‡∏Å FRONTEND: {intent}")
            interpretation = {"intent": intent, "corrected_query": query, "entity": entity, "is_complex": False, "sub_queries": [query], "location_filter": {}}
        else:
            # ‡πÉ‡∏ä‡πâ LLM ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏à‡∏ï‡∏ô‡∏≤‡πÅ‡∏•‡∏∞ Filter (Dynamic)
            logging.info(f"üß† [Router] ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ Query Interpreter ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏à‡∏ï‡∏ô‡∏≤‡πÅ‡∏•‡∏∞‡∏´‡∏≤ Location Filter...")
            interpretation = await self.query_interpreter.interpret_and_route(query)
            intent = interpretation.get("intent", "INFORMATIONAL")
            corrected_query = interpretation.get("corrected_query", query)
            entity = interpretation.get("entity")
            # Note: location_filter is inside interpretation and handled in _handle_informational via interpretation object if passed, 
            # BUT _handle_informational signature expects separate args currently? 
            # Wait, verify _handle_informational signature again.
            
            logging.info(f"üö¶ ‡πÄ‡∏à‡∏ï‡∏ô‡∏≤: {intent} | ‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô: {corrected_query} | Location Filter: {interpretation.get('location_filter')}")
        
        import sys
        
        # üÜï [LLM Routing] ‡∏ñ‡πâ‡∏≤ LLM ‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô NAVIGATE_TO ‡πÅ‡∏•‡∏∞‡∏°‡∏µ Entity ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô -> ‡πÄ‡∏ä‡∏∑‡πà‡∏≠ LLM ‡πÄ‡∏•‡∏¢
        if intent == "NAVIGATE_TO" and entity:
            logging.info(f"üó∫Ô∏è [Smart Router] LLM ‡∏£‡∏∞‡∏ö‡∏∏‡πÄ‡∏à‡∏ï‡∏ô‡∏≤ NAVIGATE_TO ‡πÑ‡∏õ‡∏¢‡∏±‡∏á: '{entity}'")
            return await self.handle_get_directions(
                entity_slug=entity, 
                user_lat=kwargs.get('user_lat', 0.0),
                user_lon=kwargs.get('user_lon', 0.0),
                skip_cleaning=True  # ‚úÖ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏ô Entity ‡∏ó‡∏µ‡πà LLM ‡∏™‡∏Å‡∏±‡∏î‡∏°‡∏≤
            )

        navigation_keywords = ["‡∏ô‡∏≥‡∏ó‡∏≤‡∏á", "‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á", "‡∏û‡∏≤‡πÑ‡∏õ", "‡∏Ç‡∏≠‡∏ó‡∏≤‡∏á", "‡πÑ‡∏õ‡∏¢‡∏±‡∏á", "‡πÑ‡∏õ‡∏ß‡∏±‡∏î", "‡πÑ‡∏õ‡∏ó‡∏µ‡πà"]
        is_nav_request = any(kw in corrected_query for kw in navigation_keywords)
        
        if is_nav_request:
            target_entity = entity
            
            # ü©π [Manual Extraction Fallback] ‡∏ñ‡πâ‡∏≤ AI ‡∏´‡∏≤ Entity ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ ‡πÉ‡∏´‡πâ‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥ Keyword ‡∏≠‡∏≠‡∏Å‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏≠‡∏≤‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠
            if not target_entity:
                for kw in navigation_keywords:
                    if kw in corrected_query:
                        # "‡∏û‡∏≤‡πÑ‡∏õ ‡∏ß‡∏±‡∏î‡∏†‡∏π‡∏°‡∏¥‡∏ô‡∏ó‡∏£‡πå" -> " ‡∏ß‡∏±‡∏î‡∏†‡∏π‡∏°‡∏¥‡∏ô‡∏ó‡∏£‡πå" -> "‡∏ß‡∏±‡∏î‡∏†‡∏π‡∏°‡∏¥‡∏ô‡∏ó‡∏£‡πå"
                        potential_entity = corrected_query.split(kw, 1)[1].strip()
                        if potential_entity:
                            target_entity = potential_entity
                            logging.info(f"üß† [Manual Entity] ‡∏™‡∏Å‡∏±‡∏î‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏≠‡∏á: '{target_entity}'")
                            break

            if not target_entity and session_id:
                last_topic = await self.session_manager.get_last_topic(session_id)
                if last_topic:
                    logging.info(f"üß† [Memory] ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏∞‡∏ö‡∏∏‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà ‡∏™‡∏±‡∏ô‡∏ô‡∏¥‡∏©‡∏ê‡∏≤‡∏ô‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î: '{last_topic}'")
                    target_entity = last_topic
                else:
                    return {"answer": "‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏Ñ‡πà‡∏∞! ‡πÅ‡∏ï‡πà‡∏ä‡πà‡∏ß‡∏¢‡∏ö‡∏≠‡∏Å‡∏ô‡πâ‡∏≠‡∏á‡∏ô‡πà‡∏≤‡∏ô‡∏´‡∏ô‡πà‡∏≠‡∏¢‡πÑ‡∏î‡πâ‡πÑ‡∏´‡∏°‡∏Ñ‡∏∞‡∏ß‡πà‡∏≤‡∏à‡∏∞‡πÉ‡∏´‡πâ **‡∏ô‡∏≥‡∏ó‡∏≤‡∏á‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡πÑ‡∏´‡∏ô?** üòä", "action": None, "sources": [], "image_url": None}

            if target_entity:
                logging.info(f"üó∫Ô∏è [Smart Router] ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡∏ó‡∏≤‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö: '{target_entity}'")
                return await self.handle_get_directions(
                    entity_slug=target_entity, 
                    user_lat=kwargs.get('user_lat', 0.0),
                    user_lon=kwargs.get('user_lon', 0.0)
                )
        
        # üéµ [Music Detection] ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Ñ‡∏≥‡∏Ç‡∏≠‡πÄ‡∏õ‡∏¥‡∏î‡πÄ‡∏û‡∏•‡∏á (Keyword Force)
        # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô LLM Router ‡∏û‡∏•‡∏≤‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏™‡∏±‡πâ‡∏ô‡πÜ
        music_keywords = ["‡πÄ‡∏õ‡∏¥‡∏î‡πÄ‡∏û‡∏•‡∏á", "‡∏ü‡∏±‡∏á‡πÄ‡∏û‡∏•‡∏á", "‡πÄ‡∏•‡πà‡∏ô‡πÄ‡∏û‡∏•‡∏á", "play music", "open music"]
        is_music_request = any(kw in corrected_query.lower() for kw in music_keywords)
        
        if is_music_request and intent != "PLAY_MUSIC":
            logging.info(f"üéµ [Smart Router] ‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏Ñ‡∏≥‡∏Ç‡∏≠‡πÄ‡∏õ‡∏¥‡∏î‡πÄ‡∏û‡∏•‡∏á: '{corrected_query}' -> Force PLAY_MUSIC")
            intent = "PLAY_MUSIC"
            
        # üßÆ [Calculator Detection] ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏Å‡πà‡∏≠‡∏ô (Hybrid Mode)
        # Pure math ‚Üí Python ‡∏ï‡∏£‡∏á | Text+math ‚Üí AI 70B ‡∏ä‡πà‡∏ß‡∏¢‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
        if calculator_service.is_calculator_query(query):
            logging.info(f"üßÆ [Calculator] ‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡πÇ‡∏à‡∏ó‡∏¢‡πå‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå: '{query}'")
            return await calculator_service.calculate(query)
        
        handler_map = {
            "WELCOME_GREETING": self._handle_welcome_flow,
            "SMALL_TALK": self._handle_small_talk,  # üëà [‡∏à‡∏∏‡∏î‡πÅ‡∏¢‡∏Å] ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô SMALL_TALK ‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏•‡πá‡∏Å (Llama 8B)
            "PLAY_MUSIC": self._handle_play_music,
            "CALCULATE": self._handle_calculate,  # üßÆ ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ñ‡∏¥‡∏î‡πÄ‡∏•‡∏Ç Python
            "INFORMATIONAL": self._handle_informational,
        }
        handler = handler_map.get(intent, self._handle_informational)
        
        response = await handler(
            corrected_query=corrected_query,
            entity=entity,
            is_complex=interpretation.get("is_complex", False),
            sub_queries=interpretation.get("sub_queries", []),
            mode=mode,
            session_id=session_id,
            turn_count=current_turn,
            ai_mode=ai_mode,   # üÜï ‡∏™‡πà‡∏á ai_mode ‡πÑ‡∏õ‡∏¢‡∏±‡∏á handlers
            interpretation=interpretation, # üÜï Send full interpretation object (with location_filter)
            original_query=query, # üÜï ‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢
            language=language, # üÜï ‡∏™‡πà‡∏á language hint ‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢
            **kwargs
        )

        # üÜï [Smart Avatar] Extract Mood & Action Tags from LLM Response
        # Pattern: [MOOD: happy], [ACTION: wave]
        if response.get("answer"):
            text = response["answer"]
            mood = "normal"
            action = None
            
            # Extract MOOD
            mood_match = re.search(r'\[MOOD:\s*(\w+)\]', text, re.IGNORECASE)
            if mood_match:
                mood = mood_match.group(1).lower()
                text = text.replace(mood_match.group(0), "").strip()
            
            # Extract ACTION
            action_match = re.search(r'\[ACTION:\s*(\w+)\]', text, re.IGNORECASE)
            if action_match:
                action = action_match.group(1).lower()
                text = text.replace(action_match.group(0), "").strip()
                
            response["answer"] = text
            response["avatar_mood"] = mood
            response["avatar_action"] = action
            
            if mood != "normal" or action:
                logging.info(f"üé≠ [Avatar] Detected Mood: {mood} | Action: {action}")

        end_time = time.perf_counter()
        processing_time = round(end_time - start_time, 2)
        response["processing_time"] = processing_time
        
        logging.info(f"‚è±Ô∏è [Performance] Total Processing Time: {processing_time}s")


        if session_id:
            primary_topic = response.pop("_primary_topic", None) 
            await self.session_manager.update_turn(
                session_id, 
                user_query=query, 
                ai_response=response.get("answer", ""), 
                topic=primary_topic
            )
            
            # üöÄ [Analytics] ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ô‡πÉ‡∏à‡∏´‡∏≤‡∏Å‡∏û‡∏ö‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠
            if primary_topic:
                await self.analytics_handler.log_interest_event(session_id, primary_topic, query)
        
        # üÜï Force show_slide to True by default if not present
        # This ensures the frontend slide-out panel appears for RAG responses
        response.setdefault("show_slide", True)
            
        return response