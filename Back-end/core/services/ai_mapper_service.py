# /core/services/ai_mapper_service.py
"""
AI Mapper Service: ‡πÉ‡∏ä‡πâ Gemini AI ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö‡∏•‡∏á Target Fields
‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AI-Powered Smart ETL System
- ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö API Key Rotation ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏à‡∏≠ Quota Error (429)
- ‡∏°‡∏µ Retry Logic ‡∏û‡∏£‡πâ‡∏≠‡∏° Exponential Backoff
"""

import json
import asyncio
from typing import List, Dict, Any, Optional
import google.generativeai as genai
from core.config import settings
from core.ai_models.key_manager import gemini_key_manager


class AIMapperService:
    """
    Service ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AI-powered data transformation
    ‡πÉ‡∏ä‡πâ Gemini ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞ extract ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏î‡∏¥‡∏ö
    ‡∏û‡∏£‡πâ‡∏≠‡∏° API Key Rotation ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏à‡∏≠ Quota Error
    """
    
    MAX_RETRIES = 4  # ‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î 4 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á (‡∏´‡∏°‡∏∏‡∏ô‡∏Ñ‡∏£‡∏ö 4 keys)
    
    def __init__(self):
        self.current_key = None
        self.model = None
        self._configure_with_next_key()
    
    def _configure_with_next_key(self) -> bool:
        """‡∏™‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡πÉ‡∏ä‡πâ API Key ‡∏ï‡∏±‡∏ß‡∏ñ‡∏±‡∏î‡πÑ‡∏õ"""
        try:
            new_key = gemini_key_manager.get_key()
            if not new_key:
                print("‚ùå [AIMapperService] No API keys available!")
                return False
            
            self.current_key = new_key
            genai.configure(api_key=new_key)
            self.model = genai.GenerativeModel(settings.GEMINI_MODEL)
            
            # ‡πÅ‡∏™‡∏î‡∏á key ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ (‡∏ã‡πà‡∏≠‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ó‡πâ‡∏≤‡∏¢)
            masked_key = new_key[:8] + "..." + new_key[-4:]
            print(f"üîë [AIMapperService] Switched to key: {masked_key}")
            return True
            
        except Exception as e:
            print(f"‚ùå [AIMapperService] Failed to configure: {e}")
            return False
    
    def _build_prompt(self, raw_data: Dict[str, Any], target_fields: List[str]) -> str:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á Prompt ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AI ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ extract ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
        # ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏õ‡πá‡∏ô text ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
        raw_text_parts = []
        for key, value in raw_data.items():
            if value and str(value).strip():
                raw_text_parts.append(f"{key}: {value}")
        raw_text = "\n".join(raw_text_parts)
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á field descriptions - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á Core ‡πÅ‡∏•‡∏∞ Detail fields
        field_descriptions = {
            # Core Fields (‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö Schema)
            "title": "‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà/‡∏£‡πâ‡∏≤‡∏ô‡∏Ñ‡πâ‡∏≤",
            "category": "‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏´‡∏•‡∏±‡∏Å ‡πÄ‡∏ä‡πà‡∏ô ‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏Å, ‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£, ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß, ‡∏ß‡∏±‡∏î",
            "topic": "‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÄ‡∏â‡∏û‡∏≤‡∏∞ ‡πÄ‡∏ä‡πà‡∏ô ‡∏Ñ‡∏≤‡πÄ‡∏ü‡πà, ‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡πÄ‡∏´‡∏ô‡∏∑‡∏≠, ‡∏ß‡∏±‡∏î‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå",
            "summary": "‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô 2-3 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ",
            "keywords": "‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ ‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢ comma",
            # Detail Fields
            "detail_overview": "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤",
            "detail_location": "‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà ‡∏û‡∏¥‡∏Å‡∏±‡∏î GPS ‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡∏ò‡∏µ‡πÄ‡∏î‡∏¥‡∏ô‡∏ó‡∏≤‡∏á",
            "detail_hours_contact": "‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ ‡πÄ‡∏ö‡∏≠‡∏£‡πå‡πÇ‡∏ó‡∏£ Line Facebook",
            "detail_highlights": "‡∏à‡∏∏‡∏î‡πÄ‡∏î‡πà‡∏ô ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏´‡πâ‡∏≤‡∏°‡∏û‡∏•‡∏≤‡∏î",
            "detail_price": "‡∏ä‡πà‡∏ß‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤ ‡∏Ñ‡πà‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡∏ä‡∏° ‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢",
            "detail_atmosphere": "‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏Å‡∏≤‡∏® ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å ‡∏™‡πÑ‡∏ï‡∏•‡πå‡∏Ç‡∏≠‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà",
            "detail_facilities": "‡∏™‡∏¥‡πà‡∏á‡∏≠‡∏≥‡∏ô‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏î‡∏ß‡∏Å ‡∏ó‡∏µ‡πà‡∏à‡∏≠‡∏î‡∏£‡∏ñ WiFi ‡∏´‡πâ‡∏≠‡∏á‡∏ô‡πâ‡∏≥",
            "detail_tips": "‡πÄ‡∏Ñ‡∏•‡πá‡∏î‡∏•‡∏±‡∏ö ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ ‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î",
        }
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ fields ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
        fields_list = []
        for field in target_fields:
            desc = field_descriptions.get(field, field)
            fields_list.append(f'  "{field}": "{desc}"')
        fields_json_hint = "{\n" + ",\n".join(fields_list) + "\n}"
        
        prompt = f"""[CONTEXT]
‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ AI Data Extraction Expert ‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô Structured JSON
‡∏†‡∏≤‡∏£‡∏Å‡∏¥‡∏à‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏•‡∏∞ extract ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö fields ‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î

[INPUT DATA - ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö]
---
{raw_text}
---

[TARGET FIELDS - ‡∏ä‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ extract]
{fields_json_hint}

[INSTRUCTIONS]
1. ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î
2. Extract ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏•‡∏á‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ field ‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î
3. ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ô‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏´‡πâ‡πÅ‡∏¢‡∏Å‡∏≠‡∏≠‡∏Å‡∏°‡∏≤ ‡πÄ‡∏ä‡πà‡∏ô "‡πÄ‡∏õ‡∏¥‡∏î 8-5 ‡πÇ‡∏°‡∏á" ‚Üí detail_hours_contact: "08:00-17:00"
4. ‡∏ñ‡πâ‡∏≤‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö field ‡πÉ‡∏î ‡πÉ‡∏´‡πâ‡πÉ‡∏™‡πà‡∏Ñ‡πà‡∏≤ null
5. **‡∏´‡πâ‡∏≤‡∏°‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏ô‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö**

[OUTPUT FORMAT]
‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON object ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡∏´‡πâ‡∏≤‡∏°‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏∑‡πà‡∏ô‡∏ô‡∏≠‡∏Å‡πÄ‡∏´‡∏ô‡∏∑‡∏≠‡∏à‡∏≤‡∏Å JSON
"""
        return prompt
    
    async def transform_row(self, raw_data: Dict[str, Any], target_fields: List[str]) -> Dict[str, Any]:
        """
        ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö 1 ‡πÅ‡∏ñ‡∏ß‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô structured data ‡∏ï‡∏≤‡∏° target fields
        ‡∏û‡∏£‡πâ‡∏≠‡∏° retry logic ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏à‡∏≠ Quota Error (429)
        """
        if not self.model:
            if not self._configure_with_next_key():
                return {field: "[Error: No API key available]" for field in target_fields}
        
        prompt = self._build_prompt(raw_data, target_fields)
        
        for attempt in range(self.MAX_RETRIES):
            try:
                # Call Gemini API
                response = await asyncio.to_thread(
                    self.model.generate_content,
                    prompt
                )
                
                # Clean and parse response
                response_text = response.text.strip()
                
                # Remove markdown code block if present
                if response_text.startswith("```json"):
                    response_text = response_text[7:]
                if response_text.startswith("```"):
                    response_text = response_text[3:]
                if response_text.endswith("```"):
                    response_text = response_text[:-3]
                response_text = response_text.strip()
                
                # Parse JSON
                extracted = json.loads(response_text)
                
                # Ensure all target fields are present
                result = {}
                for field in target_fields:
                    result[field] = extracted.get(field)
                
                return result
                
            except json.JSONDecodeError as je:
                print(f"‚ùå [AIMapperService] JSON parse error: {je}")
                return {field: "[Error: Invalid JSON response]" for field in target_fields}
                
            except Exception as e:
                error_str = str(e)
                
                # Check if it's a Quota Error (429)
                if "429" in error_str or "quota" in error_str.lower() or "exceeded" in error_str.lower():
                    print(f"‚ö†Ô∏è [AIMapperService] Quota exceeded (attempt {attempt + 1}/{self.MAX_RETRIES}), rotating key...")
                    
                    # Rotate to next API key
                    if self._configure_with_next_key():
                        # Exponential backoff: 1s, 2s, 4s, 8s
                        wait_time = min(2 ** attempt, 8)
                        print(f"‚è≥ Waiting {wait_time}s before retry...")
                        await asyncio.sleep(wait_time)
                        continue
                    else:
                        return {field: "[Error: All API keys exhausted]" for field in target_fields}
                else:
                    # Other errors - don't retry
                    print(f"‚ùå [AIMapperService] Error: {e}")
                    return {field: f"[Error: {str(e)[:50]}]" for field in target_fields}
        
        # All retries exhausted
        return {field: "[Error: Max retries exceeded]" for field in target_fields}
    
    async def transform_batch(
        self, 
        rows: List[Dict[str, Any]], 
        target_fields: List[str],
        concurrency: int = 5  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏õ‡πá‡∏ô 5 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß
    ) -> List[Dict[str, Any]]:
        """
        ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏≤‡∏¢‡πÅ‡∏ñ‡∏ß (batch processing)
        ‡πÉ‡∏ä‡πâ concurrency ‡∏ï‡πà‡∏≥‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á rate limit
        """
        results = []
        
        # Process in batches to avoid rate limiting
        for i in range(0, len(rows), concurrency):
            batch = rows[i:i + concurrency]
            
            # Create tasks for concurrent execution
            tasks = [
                self.transform_row(row, target_fields)
                for row in batch
            ]
            
            # Execute batch
            batch_results = await asyncio.gather(*tasks)
            
            # Add original data reference
            for j, result in enumerate(batch_results):
                original_row = batch[j]
                # Combine original values for reference
                original_combined = " | ".join(
                    str(v) for v in original_row.values() if v and str(v).strip()
                )
                result["_original_combined"] = original_combined
                result["_original_row"] = original_row
                results.append(result)
            
            print(f"‚úÖ [AIMapperService] Processed batch {i//concurrency + 1}, total: {len(results)}/{len(rows)}")
            
            # Increased delay between batches to avoid rate limiting
            if i + concurrency < len(rows):
                await asyncio.sleep(1.5)
        
        return results


# Singleton instance
ai_mapper_service = AIMapperService()

