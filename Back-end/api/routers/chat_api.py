import logging
from fastapi import APIRouter, HTTPException, Depends, status, File, UploadFile, WebSocket, WebSocketDisconnect
from fastapi.responses import StreamingResponse
import os
import glob
import json
from ..schemas import ChatQuery, ChatResponse 
from core.ai_models.rag_orchestrator import RAGOrchestrator
from core.config import settings
from ..dependencies import get_rag_orchestrator, get_analytics_service
from core.services.analytics_service import AnalyticsService

from core.ai_models.speech_handler import speech_handler_instance


def construct_full_image_url(image_path: str | None) -> str | None:
    if not image_path: return None
    
    # üßπ Sanitize: If DB has hardcoded localhost/127.0.0.1 (even with wrong port like 9090), strip it!
    if 'static/images' in image_path:
        # Extract just the filename or path after static/images
        filename = image_path.split('static/images/')[-1]
        return f"/static/images/{filename}"

    if image_path.startswith(('http://', 'https://')):
        return image_path
    
    if image_path.startswith('/'):
        return image_path
    
    # Default to static/images if just a filename is provided
    # üîç Check if file exists, if not try to find best match
    
    # 1. Check exact match
    full_path = settings.STATIC_DIR / "images" / image_path
    if full_path.exists():
         return f"/static/images/{image_path}" # Rel Path
         
    # 2. Try extensions
    stem = full_path.stem
    for ext in ['.jpg', '.png', '.jpeg', '.webp']:
        p = settings.STATIC_DIR / "images" / f"{stem}{ext}"
        if p.exists():
            return f"/static/images/{p.name}" # Rel Path

    # 3. Fuzzy search (Smart Match)
    # Use glob to find files containing the stem name
    # e.g. 'aom-dao' -> matches 'aom-dao-restaurant-01.jpg'
    pattern = str(settings.STATIC_DIR / "images" / f"*{stem}*")
    matches = glob.glob(pattern)
    if matches:
         # Sort by length to find the most specific or shortest match? 
         # Usually the first match is fine, or we can pick the shortest valid one.
         best_match = min(matches, key=len) 
         return f"/static/images/{os.path.basename(best_match)}" # Rel Path
    
    # Return original relative path as fallback
    return f"/static/images/{image_path}"

def sanitize_response_images(result: dict) -> dict:
    """
    Helper function to sanitize all image URLs in a ChatResponse dict.
    Applies construct_full_image_url to:
    - image_url
    - image_gallery
    - sources (image_urls key)
    """
    if not result: return result
    
    # 0. Sanitize content in Markdown Answer (The missing piece!)
    if result.get("answer"):
        import re
        # Regex to find any http(s)://.../static/images/... and replace with /static/images/...
        # This catches 127.0.0.1:9090, localhost:8014, or any other hardcoded host
        result["answer"] = re.sub(
            r'http[s]?://[^/]+/static/images/', 
            '/static/images/', 
            result["answer"]
        )

    # 1. Main Image
    if result.get("image_url"):
        result["image_url"] = construct_full_image_url(result["image_url"])

    # 2. Image Gallery
    if result.get("image_gallery"):
        raw_gallery = result.get("image_gallery", [])
        result["image_gallery"] = [construct_full_image_url(url) for url in raw_gallery if url]

    # 3. Sources
    if result.get("sources"):
        for source in result["sources"]:
            raw_urls = source.get("image_urls", []) 
            source["image_urls"] = [construct_full_image_url(url) for url in raw_urls if url]
            
    return result

router = APIRouter(tags=["Text Chat"])

@router.post("/transcribe", response_model=ChatResponse)
async def handle_audio_chat(
    orchestrator: RAGOrchestrator = Depends(get_rag_orchestrator),
    file: UploadFile = File(...)
):
    try:
        logging.info(f"üí¨ [API-Audio] ‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á: {file.filename}")
        audio_bytes = await file.read()

        transcribed_text = await speech_handler_instance.transcribe_audio_bytes(audio_bytes)
        
        if not transcribed_text:
            logging.warning("[API-Audio] ‡∏Å‡∏≤‡∏£‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤")
            return ChatResponse(answer="‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞ ‡∏ô‡πâ‡∏≠‡∏á‡∏ô‡πà‡∏≤‡∏ô‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏¢‡∏¥‡∏ô‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏û‡∏π‡∏î‡πÄ‡∏•‡∏¢ ‡∏•‡∏≠‡∏á‡∏û‡∏π‡∏î‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ô‡∏∞‡∏Ñ‡∏∞")

        logging.info(f"üëÇ [API-Audio] ‡πÑ‡∏î‡πâ‡∏¢‡∏¥‡∏ô (‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á): '{transcribed_text}'")
        
        result = await orchestrator.answer_query(transcribed_text, mode='text')
        
        if not result or "answer" not in result:
            raise HTTPException(status_code=500, detail="AI failed to generate a response.")

        if not result or "answer" not in result:
            raise HTTPException(status_code=500, detail="AI failed to generate a response.")

        # ‚úÖ Sanitize Images
        result = sanitize_response_images(result)
        
        result["transcribed_query"] = transcribed_text
        
        # üÜï Add avatar_mood based on action/content
        result["avatar_mood"] = _determine_avatar_mood(result)
        
        logging.info(f"‚úÖ [API-Audio] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÑ‡∏Ñ‡∏•‡πÄ‡∏≠‡∏ô‡∏ï‡πå (Mood: {result.get('avatar_mood')})")
        return result
    
    except Exception as e:
        logging.error(f"‚ùå [API-Audio] ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏Ñ‡∏≤‡∏î‡∏Ñ‡∏¥‡∏î: {e}", exc_info=True)
        return ChatResponse(answer="‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞ ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡πâ‡∏≤‡∏¢‡πÅ‡∏£‡∏á‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏Ñ‡πà‡∏∞")

@router.post("/stt")
async def speech_to_text_only(
    file: UploadFile = File(...)
):
    """
    üé§ Pure STT Endpoint: Returns transcribed text only.
    """
    try:
        logging.info(f"üé§ [API-STT] Received audio for transcription: {file.filename}")
        audio_bytes = await file.read()
        transcribed_text = await speech_handler_instance.transcribe_audio_bytes(audio_bytes)
        
        if not transcribed_text:
            return {"text": ""}
            
        logging.info(f"üìù [API-STT] Transcribed: '{transcribed_text}'")
        return {"text": transcribed_text}
        
    except Exception as e:
        logging.error(f"‚ùå [API-STT] Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/", response_model=ChatResponse)
async def handle_text_chat(
    query: ChatQuery, 
    orchestrator: RAGOrchestrator = Depends(get_rag_orchestrator),
    analytics: AnalyticsService = Depends(get_analytics_service)
):
    try:
        query_data = query.query 
        session_id = query.session_id 
        ai_mode = query.ai_mode or "fast"  # üÜï Read ai_mode from request
        
        result = None
        user_intent = None # To track for analytics

        if isinstance(query_data, dict) and (action := query_data.get("action")):
            # üöÄ [‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç] ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£ log session_id
            logging.info(f"‚ö°Ô∏è [API-Text] ‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö EXPLICIT ACTION: '{action}' | Session: '{session_id}' | Mode: {ai_mode}")
            
            if action == "GET_DIRECTIONS":
                entity_slug = query_data.get("entity_slug")
                user_lat = query_data.get("user_lat")
                user_lon = query_data.get("user_lon")
                
                if not entity_slug or user_lat is None or user_lon is None:
                    raise HTTPException(status_code=400, detail="Missing data for GET_DIRECTIONS")
                
                result = await orchestrator.handle_get_directions(entity_slug, user_lat, user_lon)
            
            else:
                logging.warning(f"‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö action ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å: {action}")
                result = {"answer": "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞ ‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á Action ‡∏ô‡∏µ‡πâ‡∏Ñ‡πà‡∏∞", "action": None}

        elif isinstance(query_data, str):
            logging.info(f"üí¨ [API-Text] ‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö IMPLICIT query: '{query_data}' | Session: '{session_id}' | Mode: {ai_mode}")
            result = await orchestrator.answer_query(
                query=query_data, 
                mode='text', 
                session_id=session_id,
                ai_mode=ai_mode  # üÜï Pass ai_mode to orchestrator! 
            )
        else:
            raise HTTPException(status_code=400, detail="Invalid query format.")
        
        if not result or "answer" not in result:
            raise HTTPException(status_code=500, detail="AI failed to generate a response.")
        
        # ‚úÖ Sanitize Images (Fix connection refused 9090 issues)
        result = sanitize_response_images(result)

        logging.info(f"‚úÖ [API-Text] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÑ‡∏Ñ‡∏•‡πÄ‡∏≠‡∏ô‡∏ï‡πå")
        
        # üìä Async Log to Analytics
        user_query_str = query_data if isinstance(query_data, str) else str(query_data)
        topic = result.get("category") or result.get("topic")
        location_title = result.get("title") or result.get("location_title")
        
        await analytics.log_interaction(
            session_id=session_id,
            user_query=user_query_str,
            response=result.get("answer", ""),
            topic=topic,
            location_title=location_title
        )

        # üÜï Add avatar_mood for REST API responses too
        result["avatar_mood"] = _determine_avatar_mood(result)

        return result
    
    except Exception as e:
        logging.error(f"‚ùå [API-Text] ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏Ñ‡∏≤‡∏î‡∏Ñ‡∏¥‡∏î: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="An internal error occurred.")

# üÜï Endpoint ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• province ‡∏à‡∏≤‡∏Å Toast Notification
from pydantic import BaseModel
from typing import Optional
from datetime import datetime, timezone

class WelcomeDataRequest(BaseModel):
    session_id: str
    user_province: Optional[str] = None
    user_origin: Optional[str] = "Thailand"

@router.post("/welcome-data")
async def receive_welcome_data(
    data: WelcomeDataRequest,
    analytics: AnalyticsService = Depends(get_analytics_service)
):
    """
    ‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î/‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏à‡∏≤‡∏Å Toast Notification ‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á analytics
    """
    try:
        logging.info(f"üìä [Welcome] ‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î: {data.user_province} | {data.user_origin}")
        
        # Log to analytics
        await analytics.log_interaction(
            session_id=data.session_id,
            user_query="[Welcome Form Submission]",
            response="",
            topic=None,
            location_title=None,
            user_origin=data.user_origin,
            user_province=data.user_province
        )
        
        return {"status": "success", "message": "‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏∞!"}
        
    except Exception as e:
        logging.error(f"‚ùå [Welcome] ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {e}")
        return {"status": "error", "message": str(e)}

# üÜï Music Search Endpoint - ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö in-place search
from core.ai_models.youtube_handler import youtube_handler_instance

class MusicSearchRequest(BaseModel):
    song_name: str

@router.post("/music-search")
async def search_music(request: MusicSearchRequest):
    """
    üéµ Search music on YouTube - returns results for in-place display
    """
    try:
        song_name = request.song_name.strip()
        if not song_name:
            return {"success": False, "error": "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏•‡∏á", "results": []}
        
        logging.info(f"üéµ [Music Search] ‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤: '{song_name}'")
        results = await youtube_handler_instance.search_music(query=song_name)
        
        if not results:
            return {"success": False, "error": f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÄ‡∏û‡∏•‡∏á '{song_name}'", "results": []}
        
        return {"success": True, "query": song_name, "results": results}
        
    except Exception as e:
        logging.error(f"‚ùå [Music Search] ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
        return {"success": False, "error": str(e), "results": []}

class MusicStreamRequest(BaseModel):
    video_url: str

@router.post("/music/stream")
async def get_audio_stream(request: MusicStreamRequest):
    """
    üéß Get audio stream URL for a YouTube video
    """
    try:
        video_url = request.video_url
        if not video_url:
            raise HTTPException(status_code=400, detail="Missing video_url")
            
        logging.info(f"üéß [Music Stream] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏™‡∏ï‡∏£‡∏µ‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö: {video_url}")
        
        # Reuse existing logic from youtube_handler
        stream_url = await youtube_handler_instance.get_audio_stream_url(video_url)
        
        if not stream_url:
            return {"error": "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏™‡∏ï‡∏£‡∏µ‡∏°‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ô‡∏µ‡πâ", "stream_url": None}
            
        return {"stream_url": stream_url}
        
    except Exception as e:
        logging.error(f"‚ùå [Music Stream] ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
        return {"error": str(e), "stream_url": None}

# üÜï Navigation Endpoint - ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö in-place display
class NavigationRequest(BaseModel):
    slug: Optional[str] = None
    query: Optional[str] = None
    user_lat: Optional[float] = None
    user_lon: Optional[float] = None

@router.post("/navigation")
async def get_navigation(
    request: NavigationRequest,
    orchestrator: RAGOrchestrator = Depends(get_rag_orchestrator)
):
    """
    üó∫Ô∏è Direct Navigation via HTTP for in-place updates.
    Passing a 'slug' works best. If not, 'query' acts as a fallback slug/title search.
    """
    try:
        target = request.slug or request.query
        if not target:
             return {"success": False, "error": "Missing slug or query"}

        logging.info(f"üèéÔ∏è [HTTP Nav] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ç‡∏≠‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö: '{target}'")
        
        # Directly call orchestrator logic (which calls NavigationService)
        # Note: handle_get_directions expects 'entity_slug' but it handles title fallback too
        result = await orchestrator.handle_get_directions(
            entity_slug=target,
            user_lat=request.user_lat, 
            user_lon=request.user_lon
        )
        
        # Determine success based on result content
        # NavigationService output format: { "answer": ..., "action": "SHOW_MAP_EMBED", "action_payload": ... }
        if result and result.get("action") == "SHOW_MAP_EMBED":
             return {
                 "success": True, 
                 "result": result 
             }
        else:
             return {
                 "success": False, 
                 "error": result.get("answer", "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏î‡∏±‡∏á‡∏Å‡∏•‡πà‡∏≤‡∏ß"),
                 "raw_result": result
             }

    except Exception as e:
        logging.error(f"‚ùå [HTTP Nav] ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
        return {"success": False, "error": str(e)}

# üÜï TTS Endpoint
class TTSRequest(BaseModel):
    text: str
    language: str = "th"

@router.get("/languages")
async def get_supported_languages():
    """
    Get list of supported languages and their regex patterns.
    Used by Frontend to build dynamic language detection.
    """
    from core.services.language_detector import language_detector
    return language_detector.get_active_languages_config()

@router.post("/tts")
async def text_to_speech(request: TTSRequest):
    """
    üó£Ô∏è Generate TTS audio stream from text
    """
    try:
        if not request.text:
             raise HTTPException(status_code=400, detail="Text is required")
             
        logging.info(f"üó£Ô∏è [API-TTS] Requesting TTS for: {request.text[:50]}...")
        
        return StreamingResponse(
            speech_handler_instance.synthesize_speech_stream(request.text, language_hint=request.language),
            media_type="audio/mpeg"
        )
    except Exception as e:
        logging.error(f"‚ùå [API-TTS] Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket, orchestrator: RAGOrchestrator = Depends(get_rag_orchestrator)):
    await websocket.accept()
    
    # üÜï State tracking per connection (‡∏¢‡πâ‡∏≤‡∏¢‡∏°‡∏≤‡∏à‡∏≤‡∏Å avatar_api.py)
    current_ai_mode = 'fast'
    
    try:
        while True:
            data = await websocket.receive()
            
            if "text" in data:
                try:
                    query_data = json.loads(data["text"])
                    query_text = query_data.get("query", "")
                    
                    # üîÑ Update mode if provided (‡∏¢‡πâ‡∏≤‡∏¢‡∏°‡∏≤‡∏à‡∏≤‡∏Å avatar_api.py)
                    if "ai_mode" in query_data:
                        current_ai_mode = query_data["ai_mode"]
                    
                    # üÜï Handle SET_MODE action (‡∏¢‡πâ‡∏≤‡∏¢‡∏°‡∏≤‡∏à‡∏≤‡∏Å avatar_api.py)
                    if query_data.get("action") == "SET_MODE":
                        logging.info(f"üîÑ [WS] ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÇ‡∏´‡∏°‡∏î‡πÄ‡∏õ‡πá‡∏ô: {current_ai_mode}")
                        await websocket.send_json({"status": "ok", "ai_mode": current_ai_mode})
                        continue
                    
                    # üÜï ‡∏£‡∏±‡∏ö intent ‡∏à‡∏≤‡∏Å Frontend - ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ LLM ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
                    intent = query_data.get("intent", "GENERAL")  # GENERAL | MUSIC | NAVIGATION | FAQ
                    
                    # üÜï ‡∏£‡∏±‡∏ö slug (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Navigation / System Commands
                    slug = query_data.get("slug")
                    entity_query = query_data.get("entity_query") # manual query text if slug is missing
                    language_hint = query_data.get("language", "th") # üÜï Get language hint from query_data
                    
                    # ‚õî STRICT BLOCK: Empty Query (Prevent RAG waste)
                    if not query_text.strip() and not slug and not intent == "NAVIGATION":
                         # If it's a control message or empty, don't trigger RAG
                         if query_data.get("type") in ["ping", "pong", "setMood", "changeSkin", "resumeIdle", "action"]:
                             continue
                         
                         logging.warning("‚ö†Ô∏è [WS] Empty query received. Skipping RAG.")
                         # Optional: send ack?
                         continue

                    logging.info(f"üí¨ [WS] ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: {query_text} | ‡πÇ‡∏´‡∏°‡∏î: {current_ai_mode} | ‡πÄ‡∏à‡∏ï‡∏ô‡∏≤: {intent} | Slug: {slug} | Lang: {language_hint}")
                    
                    result = await orchestrator.answer_query(
                        query_text, 
                        mode='text', 
                        ai_mode=current_ai_mode,
                        frontend_intent=intent,
                        slug=slug,
                        entity_query=entity_query,
                        language=language_hint # üÜï Pass language hint
                    )
                    # ‚úÖ Sanitize Images for WS too!
                    result = sanitize_response_images(result)
                    
                    # üÜï Add avatar_mood based on action/content (‡∏¢‡πâ‡∏≤‡∏¢‡∏°‡∏≤‡∏à‡∏≤‡∏Å avatar_api.py)
                    result["avatar_mood"] = _determine_avatar_mood(result)
                    
                    await websocket.send_json(result)
                except Exception as e:
                    logging.error(f"‚ùå [WS] ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: {e}")
                    await websocket.send_json({"answer": "‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ñ‡πà‡∏∞", "avatar_mood": "confused"})

            elif "bytes" in data:
                try:
                    audio_bytes = data["bytes"]
                    logging.info(f"üé§ [WS] ‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á: {len(audio_bytes)} bytes")
                    
                    transcribed_text = await speech_handler_instance.transcribe_audio_bytes(audio_bytes)
                    if transcribed_text:
                        logging.info(f"üëÇ [WS] ‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á: {transcribed_text}")
                        result = await orchestrator.answer_query(transcribed_text, mode='text', ai_mode=current_ai_mode)
                        # ‚úÖ Sanitize Images for Audio/WS
                        result = sanitize_response_images(result)
                        
                        result["transcribed_query"] = transcribed_text
                        # üÜï Add avatar_mood for audio responses too
                        result["avatar_mood"] = _determine_avatar_mood(result)
                        
                        await websocket.send_json(result)
                    else:
                        await websocket.send_json({"answer": "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞ ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏¢‡∏¥‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏•‡∏¢", "avatar_mood": "confused"})
                except Exception as e:
                    logging.error(f"‚ùå [WS] ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á: {e}")
                    await websocket.send_json({"answer": "‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏Ñ‡πà‡∏∞", "avatar_mood": "confused"})

    except WebSocketDisconnect:
        logging.info("üîå [WS] ‡πÑ‡∏Ñ‡∏•‡πÄ‡∏≠‡∏ô‡∏ï‡πå‡∏ï‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠")
    except RuntimeError as e:
        if "Cannot call \"receive\" once a disconnect message has been received" in str(e):
            logging.info("üîå [WS] ‡πÑ‡∏Ñ‡∏•‡πÄ‡∏≠‡∏ô‡∏ï‡πå‡∏ï‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ (‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ RuntimeError)")
        else:
            logging.error(f"‚ùå [WS] ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î Runtime: {e}")
    except Exception as e:
        logging.error(f"‚ùå [WS] ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏Ñ‡∏≤‡∏î‡∏Ñ‡∏¥‡∏î: {e}")


def _determine_avatar_mood(result: dict) -> str:
    """
    üé≠ ‡∏Å‡∏≥‡∏´‡∏ô‡∏î mood ‡∏Ç‡∏≠‡∏á Avatar ‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö (‡∏¢‡πâ‡∏≤‡∏¢‡∏°‡∏≤‡∏à‡∏≤‡∏Å avatar_api.py)
    - MUSIC action ‚Üí listening (‡πÉ‡∏™‡πà‡∏´‡∏π‡∏ü‡∏±‡∏á)
    - ‡∏°‡∏µ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û ‚Üí happy
    - ‡∏õ‡∏Å‡∏ï‡∏¥ ‚Üí talking
    """
    action = result.get("action", "")
    
    # ‡πÄ‡∏û‡∏•‡∏á = ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ü‡∏±‡∏á
    if action and "MUSIC" in action:
        return "listening"
    
    # ‡∏°‡∏µ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏´‡∏£‡∏∑‡∏≠ sources = ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏Ç
    if result.get("image_url") or result.get("image_gallery") or result.get("sources"):
        return "happy"
    
    # ‡∏õ‡∏Å‡∏ï‡∏¥ = ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏û‡∏π‡∏î
    return "talking"

