# üèóÔ∏è Architecture Deep Dive - AI Robot Guide

‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏â‡∏ö‡∏±‡∏ö‡∏ô‡∏µ‡πâ‡πÄ‡∏à‡∏≤‡∏∞‡∏•‡∏∂‡∏Å‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏°‡∏ó‡∏≤‡∏á‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ (Technical Architecture) ‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö AI Robot Guide ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ô‡∏±‡∏Å‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏á

---

## üìê System Architecture Diagram

```mermaid
graph TD
    User((User))
    
    subgraph Frontend ["Frontend Layer (HTML/JS)"]
        UI[Web UI (Chat/Avatar)]
        WS_Client[WebSocket Client]
        GSAP[GSAP Animation Engine]
        
        User <--> UI
        UI <--> GSAP
        UI <--> WS_Client
    end
    
    subgraph Backend ["Backend Layer (Python/FastAPI)"]
        WS_Server[WebSocket Endpoint]
        Router{Intent Router}
        
        subgraph Services ["Core Services"]
            Speech[Speech Handler (Whisper/TTS)]
            RAG[RAG Orchestrator]
            Nav[Navigation Service]
            IMG[Image Service]
        end
        
        subgraph AI_Brain ["AI Models"]
            LLJ[Llama-3 (Groq)]
            GEM[Gemini 2.5 (Google)]
            VDB_Model[Embedding Model (E5-Large)]
            Rerank[Cross-Encoder]
        end
        
        subgraph Data ["Data Layer"]
            Mongo[(MongoDB - Data)]
            Qdrant[(Qdrant - Vectors)]
        end
        
        WS_Client <--> |JSON/Binary| WS_Server
        WS_Server --> Speech
        Speech --> |Text Query| RAG
        RAG --> Router
        
        Router --> |Simple| LLJ
        Router --> |Complex| GEM
        Router --> |Retrieval| VDB_Model
        
        VDB_Model --> Qdrant
        RAG --> Mongo
        RAG --> Rerank
        
        RAG --> |Result| WS_Server
    end
```

---

## üß© Component Breakdown

### 1. Frontend Layer
*   **Stack:** Vanilla HTML5, CSS3, JavaScript (ES6+).
*   **Avatar Engine:** ‡πÉ‡∏ä‡πâ **GSAP (GreenSock)** ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ç‡∏±‡∏ö‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô DOM Elements (`#eye-left`, `#arm-right`) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á Animation ‡∏ó‡∏µ‡πà‡∏•‡∏∑‡πà‡∏ô‡πÑ‡∏´‡∏•
    *   `robot_avatar.js`: ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏° Logic ‡∏Å‡∏≤‡∏£‡∏Ç‡∏¢‡∏±‡∏ö (Eye Tracking, Lip Sync).
*   **Communication:** ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Backend ‡∏ú‡πà‡∏≤‡∏ô **WebSocket** (`ws://...`) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏ö‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á (Binary) ‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (JSON) ‡πÅ‡∏ö‡∏ö Real-time.

### 2. Backend Layer
*   **Stack:** Python 3.12 + FastAPI.
*   **Structure:**
    *   `/api`: Endpoints ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö HTTP ‡πÅ‡∏•‡∏∞ WebSocket.
    *   `/core`: Business Logic ‡∏´‡∏•‡∏±‡∏Å (RAG, Services).
*   **Services:**
    *   `speech_handler.py`: ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ STT (Whisper) ‡πÅ‡∏•‡∏∞ TTS (Edge TTS).
    *   `rag_orchestrator.py`: `Class` ‡∏´‡∏•‡∏±‡∏Å‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏±‡∏ô‡∏™‡∏°‡∏≠‡∏á ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏° Flow ‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏•‡∏∞‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
    *   `ai_mapper_service.py`: ‡∏£‡∏∞‡∏ö‡∏ö ETL ‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞ ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤ DB.

### 3. AI & Data Layer
*   **Models:**
    *   **Embedding:** `intfloat/multilingual-e5-large` (Local/GPU) - ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏ó‡∏¢‡πÄ‡∏õ‡πá‡∏ô Vector.
    *   **Reranker:** `BAAI/bge-reranker-base` - ‡∏à‡∏±‡∏î‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ç‡∏≠‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£.
    *   **LLM 1 (Fast):** `llama-3.1-8b-instant` (via Groq Cloud) - ‡πÄ‡∏£‡πá‡∏ß ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤.
    *   **LLM 2 (Deep):** `gemini-2.5-flash` (via Google AI) - ‡∏â‡∏•‡∏≤‡∏î ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô.
*   **Databases:**
    *   **MongoDB:** ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà (JSON), Logs, Analytics.
    *   **Qdrant:** ‡πÄ‡∏Å‡πá‡∏ö Vector Index ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ Semantic.

---

## üåä Data Flow: From Speech to Answer

1.  **Input:** User ‡∏û‡∏π‡∏î‡∏ú‡πà‡∏≤‡∏ô‡πÑ‡∏°‡∏Ñ‡πå -> Frontend ‡∏™‡πà‡∏á Binary Audio Chunks ‡∏ú‡πà‡∏≤‡∏ô WebSocket
2.  **Transcribe:** `SpeechHandler` ‡πÉ‡∏ä‡πâ Whisper ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (`transcribed_text`)
3.  **Interpret:** `QueryInterpreter` ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏à‡∏ï‡∏ô‡∏≤ (Intent) ‡∏ß‡πà‡∏≤‡∏°‡∏≤‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£ (‡∏Ñ‡∏∏‡∏¢‡πÄ‡∏•‡πà‡∏ô/‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•/‡∏ü‡∏±‡∏á‡πÄ‡∏û‡∏•‡∏á)
4.  **Retrieval (‡∏ñ‡πâ‡∏≤‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•):**
    *   ‡∏´‡∏≤‡πÉ‡∏ô **MongoDB** ‡∏î‡πâ‡∏ß‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏£‡∏á (Exact Match)
    *   ‡∏´‡∏≤‡πÉ‡∏ô **Qdrant** ‡∏î‡πâ‡∏ß‡∏¢ Vector (Semantic Search)
    *   ‡∏´‡∏≤‡πÉ‡∏ô **Trending** List
    *   ‡∏£‡∏ß‡∏°‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
5.  **Rerank:** `CrossEncoder` ‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÉ‡∏´‡∏°‡πà ‡∏Ñ‡∏±‡∏î‡πÄ‡∏â‡∏û‡∏≤‡∏∞ Top 5 ‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
6.  **Synthesize:** ‡∏™‡πà‡∏á Context + Query ‡πÄ‡∏Ç‡πâ‡∏≤ LLM (Llama/Gemini) ‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡∏ô‡πà‡∏≤‡∏ü‡∏±‡∏á
7.  **Response:**
    *   Frontend ‡∏£‡∏±‡∏ö Text -> ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
    *   Backend Stream Audio -> Frontend ‡πÄ‡∏•‡πà‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á

---

## ‚öôÔ∏è Key Technical Decisions

*   **Why Dual LLM?**
    *   Llama ‡∏ö‡∏ô Groq ‡πÄ‡∏£‡πá‡∏ß‡∏°‡∏≤‡∏Å (Latency ~300ms) ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö Voice Chat ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏° Real-time
    *   Gemini ‡∏â‡∏•‡∏≤‡∏î‡∏Å‡∏ß‡πà‡∏≤‡πÅ‡∏•‡∏∞ Context Window ‡πÉ‡∏´‡∏ç‡πà ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô PDF ‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏¢‡∏≤‡∏ß‡πÜ
*   **Why Hybrid Search?**
    *   Vector Search ‡∏ö‡∏≤‡∏á‡∏ó‡∏µ‡∏Å‡πá‡∏û‡∏•‡∏≤‡∏î‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏â‡∏û‡∏≤‡∏∞ (‡πÄ‡∏ä‡πà‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏£‡πâ‡∏≤‡∏ô‡πÅ‡∏õ‡∏•‡∏Å‡πÜ)
    *   Keyword Search (Mongo) ‡∏°‡∏≤‡∏ä‡πà‡∏ß‡∏¢‡∏≠‡∏∏‡∏î‡∏ä‡πà‡∏≠‡∏á‡πÇ‡∏´‡∏ß‡πà‡∏ô‡∏µ‡πâ ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ 100% ‡∏ñ‡πâ‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏£‡∏á
